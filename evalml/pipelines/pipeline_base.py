from collections import OrderedDict

import pandas as pd
from sklearn.model_selection import train_test_split

from .components import Estimator

from evalml.objectives import get_objective


class PipelineBase:
    def __init__(self, name, objective, component_list=[], problem_type=None, random_state=0, n_jobs=-1):
        """Machine learning pipeline made out of transformers and a estimator.

        Arguments:
            objective (Object): the objective to optimize

            component_list (list): List of components in order

            problem_type (ProblemTypes): Machine learning problem associated with the pipeline

            random_state (int): random seed/state

            n_jobs (int): Number of jobs to run in parallel
        """

        self.name = name  # autogenerated
        self.objective = get_objective(objective)
        self.random_state = random_state

        # check if one and only estimator in pipeline is the last element in component_list
        estimator = next(component for component in component_list if (isinstance(component, Estimator)))
        if estimator is not None:
            estimator_index = component_list.index(estimator)
            if estimator_index != len(component_list) - 1:
                raise RuntimeError("Estimator must be the last component in the pipeline.")

        self.component_list = component_list
        self.component_names = [comp.name for comp in component_list]
        # self.estimator_type --> get from estimator
        self.results = {}
        # todo: check if estimator_type and problem_type are compatible
        self.problem_type = problem_type
        self.n_jobs = n_jobs
        self.parameters = {}
        for component in self.component_list:
            self.parameters.update(component.parameters)

    def __getitem__(self, index):
        if isinstance(index, slice):
            return PipelineBase(name=self.name, objective=self.objective, component_list=self.component_list[index],
                                random_state=self.random_state, n_jobs=self.n_jobs)
        elif isinstance(index, int):
            return self.component_list[index]
        else:
            return self.get_component(index)

    def __setitem__(self, index, value):
        raise NotImplementedError('Setting pipeline components is not supported.')

    def get_component(self, name):
        return next((component for component in self.component_list if component.name == name), None)

    def describe(self, return_dict=False):
        """Outputs pipeline details including component parameters and cross validation information

        Returns:

            None

        """
        title = "Pipeline: " + self.name
        print(title)
        print("=" * len(title))

        better_string = "lower is better"
        if self.objective.greater_is_better:
            better_string = "greater is better"
        objective_string = "Objective: {} ({})".format(self.objective.name, better_string)
        print(objective_string)

        # Summary
        for number, component in enumerate(self.component_list, 1):
            component_string = str(number) + ". " + component.name
            print(component_string)
        print("\n")

        for component in self.component_list:
            component.describe()

        if return_dict:
            return self.parameters

    def _transform(self, X):
        X_t = X
        for component in self.component_list[:-1]:
            X_t = component.transform(X_t)
        return X_t

    def _fit(self, X, y):
        X_t = X
        y_t = y
        for component in self.component_list[:-1]:
            X_t = component.fit_transform(X_t, y_t)
        self.component_list[-1].fit(X_t, y_t)

    def fit(self, X, y, objective_fit_size=.2):
        """Build a model

        Arguments:
            X (pd.DataFrame or np.array): the input training data of shape [n_samples, n_features]

            y (pd.Series): the target training labels of length [n_samples]

            feature_types (list, optional): list of feature types. either numeric of categorical.
                categorical features will automatically be encoded

        Returns:

            self

        """
        if not isinstance(X, pd.DataFrame):
            X = pd.DataFrame(X)

        if not isinstance(y, pd.Series):
            y = pd.Series(y)

        if self.objective.needs_fitting:
            X, X_objective, y, y_objective = train_test_split(X, y, test_size=objective_fit_size, random_state=self.random_state)

        self._fit(X, y)
        self.input_feature_names = self.get_component('One Hot Encoder')._component_obj.feature_names

        if self.objective.needs_fitting:
            if self.objective.fit_needs_proba:
                y_predicted = self.predict_proba(X_objective)
            else:
                y_predicted = self.predict(X_objective)

            if self.objective.uses_extra_columns:
                self.objective.fit(y_predicted, y_objective, X_objective)
            else:
                self.objective.fit(y_predicted, y_objective)

        return self

    def predict(self, X):
        """Make predictions using selected features.

        Args:
            X (DataFrame) : features

        Returns:
            Series : estimated labels
        """
        X_t = self._transform(X)

        if self.objective and self.objective.needs_fitting:
            if self.objective.fit_needs_proba:
                y_predicted = self.predict_proba(X)
            else:
                X_t = self._transform(X)
                y_predicted = self.component_list[-1].predict(X_t)

                # y_predicted = self._predict(X)

            if self.objective.uses_extra_columns:
                return self.objective.predict(y_predicted, X)

            return self.objective.predict(y_predicted)

        return self.component_list[-1].predict(X_t)

    def predict_proba(self, X):
        """Make probability estimates for labels.

        Args:
            X (DataFrame) : features

        Returns:
            DataFrame : probability estimates
        """
        X = self._transform(X)
        proba = self.component_list[-1].predict_proba(X)
        if proba.shape[1] <= 2:
            return proba[:, 1]
        else:
            return proba

    def score(self, X, y, other_objectives=None):
        """Evaluate model performance on current and additional objectives

        Args:
            X (DataFrame) : features for model predictions
            y (Series) : true labels
            other_objectives (list): list of other objectives to score

        Returns:
            score, ordered dictionary of other objective scores
        """
        other_objectives = other_objectives or []
        other_objectives = [get_objective(o) for o in other_objectives]
        # calculate predictions only once
        y_predicted = None
        y_predicted_proba = None

        scores = []
        for objective in [self.objective] + other_objectives:
            if objective.score_needs_proba:
                if y_predicted_proba is None:
                    y_predicted_proba = self.predict_proba(X)
                y_predictions = y_predicted_proba
            else:
                if y_predicted is None:
                    y_predicted = self.predict(X)
                y_predictions = y_predicted

            if objective.uses_extra_columns:
                scores.append(objective.score(y_predictions, y, X))
            else:
                scores.append(objective.score(y_predictions, y))
        if not other_objectives:
            return scores[0], {}

        other_scores = OrderedDict(zip([n.name for n in other_objectives], scores[1:]))

        return scores[0], other_scores
