{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up pipeline search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Designing the right machine learning pipeline and picking the best parameters is a time-consuming process that relies on a mix of data science intuition as well as trial and error. EvalML streamlines the process of selecting the best modeling algorithms and parameters, so data scientists can focus their energy where it is most needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How it works\n",
    "\n",
    "EvalML selects and tunes machine learning pipelines built of numerous steps. This includes encoding categorical data, missing value imputation, feature selection, feature scaling, and finally machine learning. As EvalML tunes pipelines, it uses the objective function selected and configured by the user to guide its search. \n",
    "\n",
    "\n",
    "At each iteration, EvalML uses cross-validation to generate an estimate of the pipeline's performances. If a pipeline has high variance across cross-validation folds, it will provide a warning. In this case, the pipeline may not perform reliably in the future.\n",
    "\n",
    "EvalML is designed to work well out of the box. However, it provides numerous methods for you to control the search described below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting problem type\n",
    "\n",
    "EvalML supports both classification and regression problems. You select your problem type by importing the appropriate class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christopher.bunn/dev_envs/evalml/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import evalml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<evalml.models.auto_classifier.AutoClassifier at 0x1289bb050>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalml.AutoClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<evalml.models.auto_regressor.AutoRegressor at 0x1289d9150>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalml.AutoRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Objective Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only required parameter to start searching for pipelines is the objective function. Most domain-specific objective functions require you to specify parameters based on your business assumptions. You can do this before you initialize your pipeline search. For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<evalml.models.auto_classifier.AutoClassifier at 0x1289e2750>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evalml.objectives import FraudCost\n",
    "\n",
    "fraud_objective = FraudCost(\n",
    "    retry_percentage=.5,\n",
    "    interchange_fee=.02,\n",
    "    fraud_payout_percentage=.75,\n",
    "    amount_col='amount'\n",
    ")\n",
    "\n",
    "evalml.AutoClassifier(objective=fraud_objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on Additional Objectives\n",
    "Additional objectives can be scored on during the evaluation process. To add another objective, use the `additional_objectives` parameter in AutoClassifier or AutoRegressor. The results of these additional objectives will then appear in the results of `describe_pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<evalml.models.auto_classifier.AutoClassifier at 0x10db95550>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evalml.objectives import FraudCost\n",
    "\n",
    "fraud_objective = FraudCost(\n",
    "    retry_percentage=.5,\n",
    "    interchange_fee=.02,\n",
    "    fraud_payout_percentage=.75,\n",
    "    amount_col='amount'\n",
    ")\n",
    "\n",
    "evalml.AutoClassifier(objective='AUC', additional_objectives=[fraud_objective])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting Model Types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, all model types are considered. You can control which model types to search with the `model_types` parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = evalml.AutoClassifier(objective=\"f1\",\n",
    "                            model_types=[\"random_forest\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can see the possible pipelines that will be searched after initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[evalml.pipelines.classification.random_forest.RFClassificationPipeline]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.possible_pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can see a list of all supported models like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ModelTypes.LINEAR_MODEL: 'linear_model'>,\n",
       " <ModelTypes.XGBOOST: 'xgboost'>,\n",
       " <ModelTypes.RANDOM_FOREST: 'random_forest'>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalml.list_model_types(\"binary\") # `binary` for binary classification and `multiclass` for multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ModelTypes.LINEAR_MODEL: 'linear_model'>,\n",
       " <ModelTypes.RANDOM_FOREST: 'random_forest'>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalml.list_model_types(\"regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limiting Search Time\n",
    "\n",
    "You can limit the search time by specifying a maximum number of pipelines and/or a maximum amount of time. EvalML won't build new pipelines after the maximum time has passed or the maximum number of pipelines have been built. If a limit is not set, then a maximum of 5 pipelines will be built. \n",
    "\n",
    "The maximum search time can be specified as a integer in seconds or as a string in seconds, minutes, or hours. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<evalml.models.auto_classifier.AutoClassifier at 0x1289d73d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalml.AutoClassifier(objective=\"f1\",\n",
    "                      max_time=60)\n",
    "\n",
    "evalml.AutoClassifier(objective=\"f1\",\n",
    "                      max_time=\"1 minute\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, EvalML samples 10 sets of hyperparameters chosen randomly for each possible pipeline. Therefore, we recommend setting `max_pipelines` at least 10 times the number of possible pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_possible_pipelines = len(evalml.AutoClassifier(objective=\"f1\").possible_pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<evalml.models.auto_classifier.AutoClassifier at 0x1289d7890>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evalml.AutoClassifier(objective=\"f1\",\n",
    "                      max_time=60,\n",
    "                      max_pipelines=n_possible_pipelines*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Control Cross Validation\n",
    "\n",
    "EvalML cross-validates each model it tests during its search. By default it uses 3-fold cross-validation. You can optionally provide your own cross-validation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "clf = evalml.AutoClassifier(objective=\"f1\",\n",
    "                            cv=StratifiedKFold(5))"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
