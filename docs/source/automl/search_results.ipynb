{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring search results\n",
    "\n",
    "After finishing a pipeline search, we can inspect the results. First, let's build a search of 10 different pipelines to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m*****************************\u001b[0m\n",
      "\u001b[1m* Beginning pipeline search *\u001b[0m\n",
      "\u001b[1m*****************************\u001b[0m\n",
      "\n",
      "Optimizing for F1. Greater score is better.\n",
      "\n",
      "Searching up to 10 pipelines. No time limit is set. Set one using max_time parameter.\n",
      "\n",
      "Possible model types: xgboost, linear_model, random_forest\n",
      "\n",
      "✔ XGBoost w/ imputation:                     0%|          | Elapsed:00:00\n",
      "✔ XGBoost w/ imputation:                    10%|█         | Elapsed:00:00\n",
      "✔ Random Forest w/ imputation:              20%|██        | Elapsed:00:06\n",
      "✔ XGBoost w/ imputation:                    30%|███       | Elapsed:00:06\n",
      "✔ LogisticRegression w/ imputation + ...    40%|████      | Elapsed:00:10\n",
      "✔ XGBoost w/ imputation:                    50%|█████     | Elapsed:00:10\n",
      "✔ LogisticRegression w/ imputation + ...    60%|██████    | Elapsed:00:13\n",
      "✔ XGBoost w/ imputation:                    70%|███████   | Elapsed:00:13\n",
      "✔ LogisticRegression w/ imputation + ...    80%|████████  | Elapsed:00:17\n",
      "✔ LogisticRegression w/ imputation + ...    90%|█████████ | Elapsed:00:20\n",
      "✔ LogisticRegression w/ imputation + ...   100%|██████████| Elapsed:00:20\n",
      "\n",
      "✔ Optimization finished\n"
     ]
    }
   ],
   "source": [
    "import evalml\n",
    "\n",
    "X, y = evalml.demos.load_breast_cancer()\n",
    "\n",
    "clf = evalml.AutoClassifier(objective=\"f1\",\n",
    "                            max_pipelines=10)\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Rankings\n",
    "A summary of all the pipelines built can be returned as a dataframe. It is sorted by score. EvalML knows based on your objective function whether or not high or lower is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>score</th>\n",
       "      <th>high_variance_cv</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegressionPipeline</td>\n",
       "      <td>0.980527</td>\n",
       "      <td>False</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.5765626434012575, 'im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegressionPipeline</td>\n",
       "      <td>0.974853</td>\n",
       "      <td>False</td>\n",
       "      <td>{'penalty': 'l2', 'C': 6.239401330891865, 'imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegressionPipeline</td>\n",
       "      <td>0.974853</td>\n",
       "      <td>False</td>\n",
       "      <td>{'penalty': 'l2', 'C': 8.123565600467177, 'imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegressionPipeline</td>\n",
       "      <td>0.973411</td>\n",
       "      <td>False</td>\n",
       "      <td>{'penalty': 'l2', 'C': 8.444214828324364, 'imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>0.970674</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.38438170729269994, 'min_child_weight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>0.969254</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.6481718720511973, 'min_child_weight'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>RFClassificationPipeline</td>\n",
       "      <td>0.966846</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 569, 'max_depth': 22, 'impute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>0.965195</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.5928446182250184, 'min_child_weight'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>0.965195</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.9786183422327642, 'min_child_weight'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>0.960739</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.5288949197529046, 'min_child_weight'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               pipeline_name     score  high_variance_cv  \\\n",
       "0   8  LogisticRegressionPipeline  0.980527             False   \n",
       "1   6  LogisticRegressionPipeline  0.974853             False   \n",
       "2   9  LogisticRegressionPipeline  0.974853             False   \n",
       "3   4  LogisticRegressionPipeline  0.973411             False   \n",
       "4   1             XGBoostPipeline  0.970674             False   \n",
       "5   5             XGBoostPipeline  0.969254             False   \n",
       "6   2    RFClassificationPipeline  0.966846             False   \n",
       "7   0             XGBoostPipeline  0.965195             False   \n",
       "8   7             XGBoostPipeline  0.965195             False   \n",
       "9   3             XGBoostPipeline  0.960739             False   \n",
       "\n",
       "                                          parameters  \n",
       "0  {'penalty': 'l2', 'C': 0.5765626434012575, 'im...  \n",
       "1  {'penalty': 'l2', 'C': 6.239401330891865, 'imp...  \n",
       "2  {'penalty': 'l2', 'C': 8.123565600467177, 'imp...  \n",
       "3  {'penalty': 'l2', 'C': 8.444214828324364, 'imp...  \n",
       "4  {'eta': 0.38438170729269994, 'min_child_weight...  \n",
       "5  {'eta': 0.6481718720511973, 'min_child_weight'...  \n",
       "6  {'n_estimators': 569, 'max_depth': 22, 'impute...  \n",
       "7  {'eta': 0.5928446182250184, 'min_child_weight'...  \n",
       "8  {'eta': 0.9786183422327642, 'min_child_weight'...  \n",
       "9  {'eta': 0.5288949197529046, 'min_child_weight'...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe Pipeline\n",
    "Each pipeline is given an `id`. We can get more information about any particular pipeline using that id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m************************\u001b[0m\n",
      "\u001b[1m* Pipeline Description *\u001b[0m\n",
      "\u001b[1m************************\u001b[0m\n",
      "\n",
      "Pipeline Name: XGBoost w/ imputation\n",
      "Model type: ModelTypes.XGBOOST\n",
      "Objective: F1 (greater is better)\n",
      "Total training time (including CV): 0.3 seconds\n",
      "\n",
      "Parameters\n",
      "==========\n",
      "• eta: 0.5928446182250184\n",
      "• min_child_weight: 8.598391737229157\n",
      "• max_depth: 4\n",
      "• impute_strategy: most_frequent\n",
      "• percent_features: 0.6273280598181127\n",
      "\n",
      "Cross Validation\n",
      "=================\n",
      "               F1  Precision  Recall   AUC  Log Loss   MCC # Training # Testing\n",
      "0           0.959      0.943   0.959 0.987     0.150 0.887    379.000   190.000\n",
      "1           0.975      0.959   0.975 0.996     0.106 0.933    379.000   190.000\n",
      "2           0.962      0.974   0.962 0.983     0.134 0.899    380.000   189.000\n",
      "mean        0.965      0.959   0.965 0.988     0.130 0.906          -         -\n",
      "std         0.009      0.016   0.009 0.006     0.022 0.024          -         -\n",
      "coef of var 0.009      0.016   0.009 0.007     0.172 0.026          -         -\n"
     ]
    }
   ],
   "source": [
    "clf.describe_pipeline(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Pipeline\n",
    "You can get the object for any pipeline as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<evalml.pipelines.classification.xgboost.XGBoostPipeline at 0x13bf0efd0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_pipeline(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get best pipeline\n",
    "If you specifically want to get the best pipeline, there is a convenient access. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<evalml.pipelines.classification.logistic_regression.LogisticRegressionPipeline at 0x13e094810>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importances\n",
    "\n",
    "We can get the feature importances of the resulting pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.371201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.153827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.145848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.087861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0.052571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>0.044619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.036699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0.032339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>0.026560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>0.021891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance\n",
       "0        22    0.371201\n",
       "1        27    0.153827\n",
       "2         7    0.145848\n",
       "3        20    0.087861\n",
       "4        23    0.052571\n",
       "5        26    0.044619\n",
       "6         6    0.036699\n",
       "7        13    0.032339\n",
       "8         1    0.026583\n",
       "9        24    0.026560\n",
       "10       21    0.021891\n",
       "11        0    0.000000\n",
       "12        2    0.000000\n",
       "13        3    0.000000\n",
       "14        4    0.000000\n",
       "15        5    0.000000\n",
       "16        8    0.000000\n",
       "17        9    0.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = clf.get_pipeline(0)\n",
    "pipeline.feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access raw results\n",
    "You can also get access to all the underlying data like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'id': 0,\n",
       "  'pipeline_name': 'XGBoostPipeline',\n",
       "  'parameters': {'eta': 0.5928446182250184,\n",
       "   'min_child_weight': 8.598391737229157,\n",
       "   'max_depth': 4,\n",
       "   'impute_strategy': 'most_frequent',\n",
       "   'percent_features': 0.6273280598181127},\n",
       "  'score': 0.9651954750600785,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9586776859504134, 0.9752066115702479, 0.9617021276595743],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9586776859504134),\n",
       "                ('Precision', 0.943089430894309),\n",
       "                ('Recall', 0.9586776859504134),\n",
       "                ('AUC', 0.9865664575689431),\n",
       "                ('Log Loss', 0.14983175628279385),\n",
       "                ('MCC', 0.8871869342405617),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9752066115702479),\n",
       "                ('Precision', 0.959349593495935),\n",
       "                ('Recall', 0.9752066115702479),\n",
       "                ('AUC', 0.9955616049236596),\n",
       "                ('Log Loss', 0.10579590414111552),\n",
       "                ('MCC', 0.9327267201397125),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9617021276595743),\n",
       "                ('Precision', 0.9741379310344828),\n",
       "                ('Recall', 0.9617021276595743),\n",
       "                ('AUC', 0.9829531812725091),\n",
       "                ('Log Loss', 0.13361063377843016),\n",
       "                ('MCC', 0.8993040708411105),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 0.2605268955230713},\n",
       " 1: {'id': 1,\n",
       "  'pipeline_name': 'XGBoostPipeline',\n",
       "  'parameters': {'eta': 0.38438170729269994,\n",
       "   'min_child_weight': 3.677811458900251,\n",
       "   'max_depth': 13,\n",
       "   'impute_strategy': 'median',\n",
       "   'percent_features': 0.793807787701838},\n",
       "  'score': 0.9706738245383719,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9666666666666667, 0.979253112033195, 0.9661016949152542],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9666666666666667),\n",
       "                ('Precision', 0.9586776859504132),\n",
       "                ('Recall', 0.9666666666666667),\n",
       "                ('AUC', 0.9918333530595337),\n",
       "                ('Log Loss', 0.11837350234119712),\n",
       "                ('MCC', 0.9097672817424011),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.979253112033195),\n",
       "                ('Precision', 0.9672131147540983),\n",
       "                ('Recall', 0.979253112033195),\n",
       "                ('AUC', 0.9963309267368918),\n",
       "                ('Log Loss', 0.08243243813477946),\n",
       "                ('MCC', 0.943843520216036),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9661016949152542),\n",
       "                ('Precision', 0.9743589743589743),\n",
       "                ('Recall', 0.9661016949152542),\n",
       "                ('AUC', 0.9858343337334934),\n",
       "                ('Log Loss', 0.1252105505447145),\n",
       "                ('MCC', 0.9100059668642326),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 0.33245086669921875},\n",
       " 2: {'id': 2,\n",
       "  'pipeline_name': 'RFClassificationPipeline',\n",
       "  'parameters': {'n_estimators': 569,\n",
       "   'max_depth': 22,\n",
       "   'impute_strategy': 'most_frequent',\n",
       "   'percent_features': 0.8593661614465293},\n",
       "  'score': 0.9668456397284798,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9508196721311476, 0.979253112033195, 0.970464135021097],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9508196721311476),\n",
       "                ('Precision', 0.928),\n",
       "                ('Recall', 0.9508196721311476),\n",
       "                ('AUC', 0.9889336016096579),\n",
       "                ('Log Loss', 0.1388421748025717),\n",
       "                ('MCC', 0.8647724688764672),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.979253112033195),\n",
       "                ('Precision', 0.9672131147540983),\n",
       "                ('Recall', 0.979253112033195),\n",
       "                ('AUC', 0.9898804592259438),\n",
       "                ('Log Loss', 0.11232987225229708),\n",
       "                ('MCC', 0.943843520216036),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.970464135021097),\n",
       "                ('Precision', 0.9745762711864406),\n",
       "                ('Recall', 0.970464135021097),\n",
       "                ('AUC', 0.9906362545018007),\n",
       "                ('Log Loss', 0.11575295379524118),\n",
       "                ('MCC', 0.9208800271662652),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 6.14126992225647},\n",
       " 3: {'id': 3,\n",
       "  'pipeline_name': 'XGBoostPipeline',\n",
       "  'parameters': {'eta': 0.5288949197529046,\n",
       "   'min_child_weight': 6.112401049845392,\n",
       "   'max_depth': 6,\n",
       "   'impute_strategy': 'most_frequent',\n",
       "   'percent_features': 0.34402219881309576},\n",
       "  'score': 0.9607393479447351,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9504132231404958, 0.9794238683127572, 0.9523809523809523],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9504132231404958),\n",
       "                ('Precision', 0.9349593495934959),\n",
       "                ('Recall', 0.9504132231404958),\n",
       "                ('AUC', 0.9865664575689431),\n",
       "                ('Log Loss', 0.14135858728060205),\n",
       "                ('MCC', 0.8644170412909863),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9794238683127572),\n",
       "                ('Precision', 0.9596774193548387),\n",
       "                ('Recall', 0.9794238683127572),\n",
       "                ('AUC', 0.9960350337318026),\n",
       "                ('Log Loss', 0.08963871603513038),\n",
       "                ('MCC', 0.9445075449666159),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9523809523809523),\n",
       "                ('Precision', 0.9821428571428571),\n",
       "                ('Recall', 0.9523809523809523),\n",
       "                ('AUC', 0.985954381752701),\n",
       "                ('Log Loss', 0.13301814707838708),\n",
       "                ('MCC', 0.8803966271554114),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 0.25251102447509766},\n",
       " 4: {'id': 4,\n",
       "  'pipeline_name': 'LogisticRegressionPipeline',\n",
       "  'parameters': {'penalty': 'l2',\n",
       "   'C': 8.444214828324364,\n",
       "   'impute_strategy': 'most_frequent'},\n",
       "  'score': 0.9734109818152151,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.970464135021097, 0.9754098360655737, 0.9743589743589743],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.970464135021097),\n",
       "                ('Precision', 0.9745762711864406),\n",
       "                ('Recall', 0.970464135021097),\n",
       "                ('AUC', 0.9885193514025328),\n",
       "                ('Log Loss', 0.19432945908194826),\n",
       "                ('MCC', 0.9215733295732883),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9754098360655737),\n",
       "                ('Precision', 0.952),\n",
       "                ('Recall', 0.9754098360655737),\n",
       "                ('AUC', 0.9849686353414605),\n",
       "                ('Log Loss', 0.1533799764176718),\n",
       "                ('MCC', 0.933568045604951),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9743589743589743),\n",
       "                ('Precision', 0.991304347826087),\n",
       "                ('Recall', 0.9743589743589743),\n",
       "                ('AUC', 0.990516206482593),\n",
       "                ('Log Loss', 0.1164316714613046),\n",
       "                ('MCC', 0.9336637889421326),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 3.094980001449585},\n",
       " 5: {'id': 5,\n",
       "  'pipeline_name': 'XGBoostPipeline',\n",
       "  'parameters': {'eta': 0.6481718720511973,\n",
       "   'min_child_weight': 4.314173858564932,\n",
       "   'max_depth': 6,\n",
       "   'impute_strategy': 'most_frequent',\n",
       "   'percent_features': 0.871312026764351},\n",
       "  'score': 0.969254157920668,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9623430962343097, 0.9752066115702479, 0.9702127659574468],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9623430962343097),\n",
       "                ('Precision', 0.9583333333333334),\n",
       "                ('Recall', 0.9623430962343097),\n",
       "                ('AUC', 0.9901763522310333),\n",
       "                ('Log Loss', 0.12383983944248604),\n",
       "                ('MCC', 0.8985734479173947),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9752066115702479),\n",
       "                ('Precision', 0.959349593495935),\n",
       "                ('Recall', 0.9752066115702479),\n",
       "                ('AUC', 0.9962125695348562),\n",
       "                ('Log Loss', 0.08514171470765416),\n",
       "                ('MCC', 0.9327267201397125),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9702127659574468),\n",
       "                ('Precision', 0.9827586206896551),\n",
       "                ('Recall', 0.9702127659574468),\n",
       "                ('AUC', 0.9860744297719087),\n",
       "                ('Log Loss', 0.12377072123640645),\n",
       "                ('MCC', 0.9218075091290715),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 0.35909104347229004},\n",
       " 6: {'id': 6,\n",
       "  'pipeline_name': 'LogisticRegressionPipeline',\n",
       "  'parameters': {'penalty': 'l2',\n",
       "   'C': 6.239401330891865,\n",
       "   'impute_strategy': 'median'},\n",
       "  'score': 0.9748529087969783,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9747899159663865, 0.9754098360655737, 0.9743589743589743],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9747899159663865),\n",
       "                ('Precision', 0.9747899159663865),\n",
       "                ('Recall', 0.9747899159663865),\n",
       "                ('AUC', 0.9889927802106758),\n",
       "                ('Log Loss', 0.174912415672324),\n",
       "                ('MCC', 0.932536394839626),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9754098360655737),\n",
       "                ('Precision', 0.952),\n",
       "                ('Recall', 0.9754098360655737),\n",
       "                ('AUC', 0.9870990649781038),\n",
       "                ('Log Loss', 0.13982009938626028),\n",
       "                ('MCC', 0.933568045604951),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9743589743589743),\n",
       "                ('Precision', 0.991304347826087),\n",
       "                ('Recall', 0.9743589743589743),\n",
       "                ('AUC', 0.990516206482593),\n",
       "                ('Log Loss', 0.11096455834029183),\n",
       "                ('MCC', 0.9336637889421326),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 3.22955584526062},\n",
       " 7: {'id': 7,\n",
       "  'pipeline_name': 'XGBoostPipeline',\n",
       "  'parameters': {'eta': 0.9786183422327642,\n",
       "   'min_child_weight': 8.192427077950514,\n",
       "   'max_depth': 20,\n",
       "   'impute_strategy': 'median',\n",
       "   'percent_features': 0.6820907348177707},\n",
       "  'score': 0.9651954750600785,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9586776859504134, 0.9752066115702479, 0.9617021276595743],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9586776859504134),\n",
       "                ('Precision', 0.943089430894309),\n",
       "                ('Recall', 0.9586776859504134),\n",
       "                ('AUC', 0.986566457568943),\n",
       "                ('Log Loss', 0.1476227625175134),\n",
       "                ('MCC', 0.8871869342405617),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9752066115702479),\n",
       "                ('Precision', 0.959349593495935),\n",
       "                ('Recall', 0.9752066115702479),\n",
       "                ('AUC', 0.9962125695348562),\n",
       "                ('Log Loss', 0.09923503662116434),\n",
       "                ('MCC', 0.9327267201397125),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9617021276595743),\n",
       "                ('Precision', 0.9741379310344828),\n",
       "                ('Recall', 0.9617021276595743),\n",
       "                ('AUC', 0.9834333733493397),\n",
       "                ('Log Loss', 0.13148702966620918),\n",
       "                ('MCC', 0.8993040708411105),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 0.2930469512939453},\n",
       " 8: {'id': 8,\n",
       "  'pipeline_name': 'LogisticRegressionPipeline',\n",
       "  'parameters': {'penalty': 'l2',\n",
       "   'C': 0.5765626434012575,\n",
       "   'impute_strategy': 'mean'},\n",
       "  'score': 0.9805269796885542,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9874476987447698, 0.9754098360655737, 0.9787234042553192],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9874476987447698),\n",
       "                ('Precision', 0.9833333333333333),\n",
       "                ('Recall', 0.9874476987447698),\n",
       "                ('AUC', 0.994910640312463),\n",
       "                ('Log Loss', 0.08726565374201165),\n",
       "                ('MCC', 0.9662335358054943),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9754098360655737),\n",
       "                ('Precision', 0.952),\n",
       "                ('Recall', 0.9754098360655737),\n",
       "                ('AUC', 0.9979879275653923),\n",
       "                ('Log Loss', 0.07645591278007538),\n",
       "                ('MCC', 0.933568045604951),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9787234042553192),\n",
       "                ('Precision', 0.9913793103448276),\n",
       "                ('Recall', 0.9787234042553192),\n",
       "                ('AUC', 0.9903961584633854),\n",
       "                ('Log Loss', 0.09774553003325112),\n",
       "                ('MCC', 0.9443109474170326),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 3.4265527725219727},\n",
       " 9: {'id': 9,\n",
       "  'pipeline_name': 'LogisticRegressionPipeline',\n",
       "  'parameters': {'penalty': 'l2',\n",
       "   'C': 8.123565600467177,\n",
       "   'impute_strategy': 'median'},\n",
       "  'score': 0.9748529087969783,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9747899159663865, 0.9754098360655737, 0.9743589743589743],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9747899159663865),\n",
       "                ('Precision', 0.9747899159663865),\n",
       "                ('Recall', 0.9747899159663865),\n",
       "                ('AUC', 0.9886377086045686),\n",
       "                ('Log Loss', 0.1917051028291318),\n",
       "                ('MCC', 0.932536394839626),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9754098360655737),\n",
       "                ('Precision', 0.952),\n",
       "                ('Recall', 0.9754098360655737),\n",
       "                ('AUC', 0.9850869925434962),\n",
       "                ('Log Loss', 0.15159254810086167),\n",
       "                ('MCC', 0.933568045604951),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9743589743589743),\n",
       "                ('Precision', 0.991304347826087),\n",
       "                ('Recall', 0.9743589743589743),\n",
       "                ('AUC', 0.990516206482593),\n",
       "                ('Log Loss', 0.1156693063457744),\n",
       "                ('MCC', 0.9336637889421326),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 3.400575876235962}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
