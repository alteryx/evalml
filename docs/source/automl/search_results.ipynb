{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring search results\n",
    "\n",
    "After finishing a pipeline search, we can inspect the results. First, let's build a search of 10 different pipelines to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m*****************************\u001b[0m\n",
      "\u001b[1m* Beginning pipeline search *\u001b[0m\n",
      "\u001b[1m*****************************\u001b[0m\n",
      "\n",
      "Optimizing for F1. Greater score is better.\n",
      "\n",
      "Searching up to 10 pipelines. \n",
      "Possible model types: random_forest, xgboost, linear_model\n",
      "\n",
      "✔ XGBoost Classifier w/ One Hot Encod...     0%|          | Elapsed:00:02\n",
      "✔ XGBoost Classifier w/ One Hot Encod...    10%|█         | Elapsed:00:04\n",
      "✔ Random Forest Classifier w/ One Hot...    20%|██        | Elapsed:00:14\n",
      "✔ XGBoost Classifier w/ One Hot Encod...    30%|███       | Elapsed:00:16\n",
      "✔ Logistic Regression Classifier w/ O...    40%|████      | Elapsed:00:22\n",
      "✔ XGBoost Classifier w/ One Hot Encod...    50%|█████     | Elapsed:00:24\n",
      "✔ Logistic Regression Classifier w/ O...    60%|██████    | Elapsed:00:30\n",
      "✔ XGBoost Classifier w/ One Hot Encod...    70%|███████   | Elapsed:00:32\n",
      "✔ Logistic Regression Classifier w/ O...    80%|████████  | Elapsed:00:38\n",
      "✔ Logistic Regression Classifier w/ O...    90%|█████████ | Elapsed:00:44\n",
      "✔ Logistic Regression Classifier w/ O...   100%|██████████| Elapsed:00:44\n",
      "\n",
      "✔ Optimization finished\n"
     ]
    }
   ],
   "source": [
    "import evalml\n",
    "\n",
    "X, y = evalml.demos.load_breast_cancer()\n",
    "\n",
    "clf = evalml.AutoClassifier(objective=\"f1\",\n",
    "                            max_pipelines=10)\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Rankings\n",
    "A summary of all the pipelines built can be returned as a dataframe. It is sorted by score. EvalML knows based on your objective function whether or not high or lower is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>score</th>\n",
       "      <th>high_variance_cv</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegressionPipeline</td>\n",
       "      <td>0.980527</td>\n",
       "      <td>False</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.5765626434012575, 'im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegressionPipeline</td>\n",
       "      <td>0.974853</td>\n",
       "      <td>False</td>\n",
       "      <td>{'penalty': 'l2', 'C': 6.239401330891865, 'imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegressionPipeline</td>\n",
       "      <td>0.974853</td>\n",
       "      <td>False</td>\n",
       "      <td>{'penalty': 'l2', 'C': 8.123565600467177, 'imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegressionPipeline</td>\n",
       "      <td>0.973411</td>\n",
       "      <td>False</td>\n",
       "      <td>{'penalty': 'l2', 'C': 8.444214828324364, 'imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>0.970626</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.38438170729269994, 'min_child_weight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>RFClassificationPipeline</td>\n",
       "      <td>0.966846</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 569, 'max_depth': 22, 'impute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>0.966592</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.6481718720511973, 'min_child_weight'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>0.965192</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.5928446182250184, 'min_child_weight'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>0.963913</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.9786183422327642, 'min_child_weight'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>0.952237</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.5288949197529046, 'min_child_weight'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               pipeline_name     score  high_variance_cv  \\\n",
       "0   8  LogisticRegressionPipeline  0.980527             False   \n",
       "1   6  LogisticRegressionPipeline  0.974853             False   \n",
       "2   9  LogisticRegressionPipeline  0.974853             False   \n",
       "3   4  LogisticRegressionPipeline  0.973411             False   \n",
       "4   1             XGBoostPipeline  0.970626             False   \n",
       "5   2    RFClassificationPipeline  0.966846             False   \n",
       "6   5             XGBoostPipeline  0.966592             False   \n",
       "7   0             XGBoostPipeline  0.965192             False   \n",
       "8   7             XGBoostPipeline  0.963913             False   \n",
       "9   3             XGBoostPipeline  0.952237             False   \n",
       "\n",
       "                                          parameters  \n",
       "0  {'penalty': 'l2', 'C': 0.5765626434012575, 'im...  \n",
       "1  {'penalty': 'l2', 'C': 6.239401330891865, 'imp...  \n",
       "2  {'penalty': 'l2', 'C': 8.123565600467177, 'imp...  \n",
       "3  {'penalty': 'l2', 'C': 8.444214828324364, 'imp...  \n",
       "4  {'eta': 0.38438170729269994, 'min_child_weight...  \n",
       "5  {'n_estimators': 569, 'max_depth': 22, 'impute...  \n",
       "6  {'eta': 0.6481718720511973, 'min_child_weight'...  \n",
       "7  {'eta': 0.5928446182250184, 'min_child_weight'...  \n",
       "8  {'eta': 0.9786183422327642, 'min_child_weight'...  \n",
       "9  {'eta': 0.5288949197529046, 'min_child_weight'...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe Pipeline\n",
    "Each pipeline is given an `id`. We can get more information about any particular pipeline using that id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m********************************************************************************************\u001b[0m\n",
      "\u001b[1m* XGBoost Classifier w/ One Hot Encoder + Simple Imputer + RF Classifier Select From Model *\u001b[0m\n",
      "\u001b[1m********************************************************************************************\u001b[0m\n",
      "\n",
      "Pipeline Name: XGBoost Classifier w/ One Hot Encoder + Simple Imputer + RF Classifier Select From Model\n",
      "Model type: ModelTypes.XGBOOST\n",
      "Objective: F1 (greater is better)\n",
      "Total training time (including CV): 2.4 seconds\n",
      "\n",
      "Pipeline Steps\n",
      "==============\n",
      "1. One Hot Encoder\n",
      "2. Simple Imputer\n",
      "\t * impute_strategy : most_frequent\n",
      "3. RF Classifier Select From Model\n",
      "\t * percent_features : 0.6273280598181127\n",
      "\t * threshold : -inf\n",
      "4. XGBoost Classifier\n",
      "\t * eta : 0.5928446182250184\n",
      "\t * max_depth : 4\n",
      "\t * min_child_weight : 8.598391737229157\n",
      "\n",
      "Training\n",
      "========\n",
      "Training for Binary Classification problems.\n",
      "Total training time (including CV): 0.2 seconds\n",
      "\n",
      "Cross Validation\n",
      "----------------\n",
      "               F1  Precision  Recall   AUC  Log Loss   MCC # Training # Testing\n",
      "0           0.950      0.935   0.950 0.985     0.154 0.864    379.000   190.000\n",
      "1           0.975      0.959   0.975 0.996     0.102 0.933    379.000   190.000\n",
      "2           0.970      0.991   0.970 0.983     0.137 0.923    380.000   189.000\n",
      "mean        0.965      0.962   0.965 0.988     0.131 0.907          -         -\n",
      "std         0.013      0.028   0.013 0.007     0.026 0.037          -         -\n",
      "coef of var 0.014      0.029   0.014 0.007     0.202 0.041          -         -\n"
     ]
    }
   ],
   "source": [
    "clf.describe_pipeline(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Pipeline\n",
    "You can get the object for any pipeline as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<evalml.pipelines.classification.xgboost.XGBoostPipeline at 0x1292d9a90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_pipeline(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get best pipeline\n",
    "If you specifically want to get the best pipeline, there is a convenient access. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<evalml.pipelines.classification.logistic_regression.LogisticRegressionPipeline at 0x12b4bc250>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importances\n",
    "\n",
    "We can get the feature importances of the resulting pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.407441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.239457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>0.120609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.072031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0.052818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.038344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>0.028949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.003987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>0.002403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>29</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance\n",
       "0        22    0.407441\n",
       "1         7    0.239457\n",
       "2        27    0.120609\n",
       "3        20    0.072031\n",
       "4        23    0.052818\n",
       "5         6    0.038344\n",
       "6         1    0.033962\n",
       "7        21    0.028949\n",
       "8         4    0.003987\n",
       "9        25    0.002403\n",
       "10        0    0.000000\n",
       "11        2    0.000000\n",
       "12        3    0.000000\n",
       "13       12    0.000000\n",
       "14       13    0.000000\n",
       "15       18    0.000000\n",
       "16       19    0.000000\n",
       "17       29    0.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = clf.get_pipeline(0)\n",
    "pipeline.feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the feature importances as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11e90c1bc86d475caaf8ea7c55165a80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'orientation': 'h',\n",
       "              'type': 'bar',\n",
       "              'uid': '62d6324d-3…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline.plot_feature_importances()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access raw results\n",
    "You can also get access to all the underlying data like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'id': 0,\n",
       "  'pipeline_name': 'XGBoostPipeline',\n",
       "  'parameters': {'eta': 0.5928446182250184,\n",
       "   'min_child_weight': 8.598391737229157,\n",
       "   'max_depth': 4,\n",
       "   'impute_strategy': 'most_frequent',\n",
       "   'percent_features': 0.6273280598181127},\n",
       "  'score': 0.9651923054186028,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9504132231404958, 0.9752066115702479, 0.9699570815450643],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9504132231404958),\n",
       "                ('Precision', 0.9349593495934959),\n",
       "                ('Recall', 0.9504132231404958),\n",
       "                ('AUC', 0.984731920937389),\n",
       "                ('Log Loss', 0.1536501646237938),\n",
       "                ('MCC', 0.8644170412909863),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9752066115702479),\n",
       "                ('Precision', 0.959349593495935),\n",
       "                ('Recall', 0.9752066115702479),\n",
       "                ('AUC', 0.9960350337318026),\n",
       "                ('Log Loss', 0.10194972519713798),\n",
       "                ('MCC', 0.9327267201397125),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9699570815450643),\n",
       "                ('Precision', 0.9912280701754386),\n",
       "                ('Recall', 0.9699570815450643),\n",
       "                ('AUC', 0.983313325330132),\n",
       "                ('Log Loss', 0.13664108953345075),\n",
       "                ('MCC', 0.9231826763268304),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 2.4425532817840576},\n",
       " 1: {'id': 1,\n",
       "  'pipeline_name': 'XGBoostPipeline',\n",
       "  'parameters': {'eta': 0.38438170729269994,\n",
       "   'min_child_weight': 3.677811458900251,\n",
       "   'max_depth': 13,\n",
       "   'impute_strategy': 'median',\n",
       "   'percent_features': 0.793807787701838},\n",
       "  'score': 0.9706261399583499,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9707112970711297, 0.9709543568464729, 0.9702127659574468],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9707112970711297),\n",
       "                ('Precision', 0.9666666666666667),\n",
       "                ('Recall', 0.9707112970711297),\n",
       "                ('AUC', 0.9917149958574978),\n",
       "                ('Log Loss', 0.11573912222489813),\n",
       "                ('MCC', 0.9211268105467613),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9709543568464729),\n",
       "                ('Precision', 0.9590163934426229),\n",
       "                ('Recall', 0.9709543568464729),\n",
       "                ('AUC', 0.9969227127470707),\n",
       "                ('Log Loss', 0.07704140599817037),\n",
       "                ('MCC', 0.9211492315750531),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9702127659574468),\n",
       "                ('Precision', 0.9827586206896551),\n",
       "                ('Recall', 0.9702127659574468),\n",
       "                ('AUC', 0.9857142857142858),\n",
       "                ('Log Loss', 0.12628072744331484),\n",
       "                ('MCC', 0.9218075091290715),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 2.5321948528289795},\n",
       " 2: {'id': 2,\n",
       "  'pipeline_name': 'RFClassificationPipeline',\n",
       "  'parameters': {'n_estimators': 569,\n",
       "   'max_depth': 22,\n",
       "   'impute_strategy': 'most_frequent',\n",
       "   'percent_features': 0.8593661614465293},\n",
       "  'score': 0.9668456397284798,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9508196721311476, 0.979253112033195, 0.970464135021097],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9508196721311476),\n",
       "                ('Precision', 0.928),\n",
       "                ('Recall', 0.9508196721311476),\n",
       "                ('AUC', 0.9889336016096579),\n",
       "                ('Log Loss', 0.1388421748025717),\n",
       "                ('MCC', 0.8647724688764672),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.979253112033195),\n",
       "                ('Precision', 0.9672131147540983),\n",
       "                ('Recall', 0.979253112033195),\n",
       "                ('AUC', 0.9898804592259438),\n",
       "                ('Log Loss', 0.11232987225229708),\n",
       "                ('MCC', 0.943843520216036),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.970464135021097),\n",
       "                ('Precision', 0.9745762711864406),\n",
       "                ('Recall', 0.970464135021097),\n",
       "                ('AUC', 0.9906362545018007),\n",
       "                ('Log Loss', 0.11575295379524118),\n",
       "                ('MCC', 0.9208800271662652),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 9.48002290725708},\n",
       " 3: {'id': 3,\n",
       "  'pipeline_name': 'XGBoostPipeline',\n",
       "  'parameters': {'eta': 0.5288949197529046,\n",
       "   'min_child_weight': 6.112401049845392,\n",
       "   'max_depth': 6,\n",
       "   'impute_strategy': 'most_frequent',\n",
       "   'percent_features': 0.34402219881309576},\n",
       "  'score': 0.9522372250281359,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9367088607594938, 0.9672131147540983, 0.9527896995708156],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9367088607594938),\n",
       "                ('Precision', 0.940677966101695),\n",
       "                ('Recall', 0.9367088607594938),\n",
       "                ('AUC', 0.9821872410936205),\n",
       "                ('Log Loss', 0.16857726289155453),\n",
       "                ('MCC', 0.8318710075349047),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9672131147540983),\n",
       "                ('Precision', 0.944),\n",
       "                ('Recall', 0.9672131147540983),\n",
       "                ('AUC', 0.9937270682921056),\n",
       "                ('Log Loss', 0.10433676971098114),\n",
       "                ('MCC', 0.9106361866954563),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9527896995708156),\n",
       "                ('Precision', 0.9736842105263158),\n",
       "                ('Recall', 0.9527896995708156),\n",
       "                ('AUC', 0.9845138055222089),\n",
       "                ('Log Loss', 0.14270813120701523),\n",
       "                ('MCC', 0.8783921421654207),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 2.4046850204467773},\n",
       " 4: {'id': 4,\n",
       "  'pipeline_name': 'LogisticRegressionPipeline',\n",
       "  'parameters': {'penalty': 'l2',\n",
       "   'C': 8.444214828324364,\n",
       "   'impute_strategy': 'most_frequent'},\n",
       "  'score': 0.9734109818152151,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.970464135021097, 0.9754098360655737, 0.9743589743589743],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.970464135021097),\n",
       "                ('Precision', 0.9745762711864406),\n",
       "                ('Recall', 0.970464135021097),\n",
       "                ('AUC', 0.9885193514025328),\n",
       "                ('Log Loss', 0.1943294590819038),\n",
       "                ('MCC', 0.9215733295732883),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9754098360655737),\n",
       "                ('Precision', 0.952),\n",
       "                ('Recall', 0.9754098360655737),\n",
       "                ('AUC', 0.9849686353414605),\n",
       "                ('Log Loss', 0.1533799764176819),\n",
       "                ('MCC', 0.933568045604951),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9743589743589743),\n",
       "                ('Precision', 0.991304347826087),\n",
       "                ('Recall', 0.9743589743589743),\n",
       "                ('AUC', 0.990516206482593),\n",
       "                ('Log Loss', 0.1164316714613053),\n",
       "                ('MCC', 0.9336637889421326),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 5.392014980316162},\n",
       " 5: {'id': 5,\n",
       "  'pipeline_name': 'XGBoostPipeline',\n",
       "  'parameters': {'eta': 0.6481718720511973,\n",
       "   'min_child_weight': 4.314173858564932,\n",
       "   'max_depth': 6,\n",
       "   'impute_strategy': 'most_frequent',\n",
       "   'percent_features': 0.871312026764351},\n",
       "  'score': 0.966592074666908,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9543568464730291, 0.9752066115702479, 0.9702127659574468],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9543568464730291),\n",
       "                ('Precision', 0.9426229508196722),\n",
       "                ('Recall', 0.9543568464730291),\n",
       "                ('AUC', 0.9899396378269618),\n",
       "                ('Log Loss', 0.12702225128151967),\n",
       "                ('MCC', 0.8757606542930872),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9752066115702479),\n",
       "                ('Precision', 0.959349593495935),\n",
       "                ('Recall', 0.9752066115702479),\n",
       "                ('AUC', 0.9965676411409634),\n",
       "                ('Log Loss', 0.0801103590350402),\n",
       "                ('MCC', 0.9327267201397125),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9702127659574468),\n",
       "                ('Precision', 0.9827586206896551),\n",
       "                ('Recall', 0.9702127659574468),\n",
       "                ('AUC', 0.9858343337334934),\n",
       "                ('Log Loss', 0.1270006743029361),\n",
       "                ('MCC', 0.9218075091290715),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 2.5001349449157715},\n",
       " 6: {'id': 6,\n",
       "  'pipeline_name': 'LogisticRegressionPipeline',\n",
       "  'parameters': {'penalty': 'l2',\n",
       "   'C': 6.239401330891865,\n",
       "   'impute_strategy': 'median'},\n",
       "  'score': 0.9748529087969783,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9747899159663865, 0.9754098360655737, 0.9743589743589743],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9747899159663865),\n",
       "                ('Precision', 0.9747899159663865),\n",
       "                ('Recall', 0.9747899159663865),\n",
       "                ('AUC', 0.9889927802106758),\n",
       "                ('Log Loss', 0.17491241567239438),\n",
       "                ('MCC', 0.932536394839626),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9754098360655737),\n",
       "                ('Precision', 0.952),\n",
       "                ('Recall', 0.9754098360655737),\n",
       "                ('AUC', 0.9870990649781038),\n",
       "                ('Log Loss', 0.13982009938625542),\n",
       "                ('MCC', 0.933568045604951),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9743589743589743),\n",
       "                ('Precision', 0.991304347826087),\n",
       "                ('Recall', 0.9743589743589743),\n",
       "                ('AUC', 0.990516206482593),\n",
       "                ('Log Loss', 0.1109645583402926),\n",
       "                ('MCC', 0.9336637889421326),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 5.3540239334106445},\n",
       " 7: {'id': 7,\n",
       "  'pipeline_name': 'XGBoostPipeline',\n",
       "  'parameters': {'eta': 0.9786183422327642,\n",
       "   'min_child_weight': 8.192427077950514,\n",
       "   'max_depth': 20,\n",
       "   'impute_strategy': 'median',\n",
       "   'percent_features': 0.6820907348177707},\n",
       "  'score': 0.9639126305792973,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9547325102880658, 0.9711934156378601, 0.9658119658119659],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9547325102880658),\n",
       "                ('Precision', 0.9354838709677419),\n",
       "                ('Recall', 0.9547325102880658),\n",
       "                ('AUC', 0.9853237069475678),\n",
       "                ('Log Loss', 0.15021697619047605),\n",
       "                ('MCC', 0.8759603969361893),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9711934156378601),\n",
       "                ('Precision', 0.9516129032258065),\n",
       "                ('Recall', 0.9711934156378601),\n",
       "                ('AUC', 0.9950289975144987),\n",
       "                ('Log Loss', 0.10607622409680564),\n",
       "                ('MCC', 0.9216584956231404),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9658119658119659),\n",
       "                ('Precision', 0.9826086956521739),\n",
       "                ('Recall', 0.9658119658119659),\n",
       "                ('AUC', 0.9834333733493397),\n",
       "                ('Log Loss', 0.13131227825704234),\n",
       "                ('MCC', 0.9112159507396058),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 2.449913263320923},\n",
       " 8: {'id': 8,\n",
       "  'pipeline_name': 'LogisticRegressionPipeline',\n",
       "  'parameters': {'penalty': 'l2',\n",
       "   'C': 0.5765626434012575,\n",
       "   'impute_strategy': 'mean'},\n",
       "  'score': 0.9805269796885542,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9874476987447698, 0.9754098360655737, 0.9787234042553192],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9874476987447698),\n",
       "                ('Precision', 0.9833333333333333),\n",
       "                ('Recall', 0.9874476987447698),\n",
       "                ('AUC', 0.994910640312463),\n",
       "                ('Log Loss', 0.08726565374201126),\n",
       "                ('MCC', 0.9662335358054943),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9754098360655737),\n",
       "                ('Precision', 0.952),\n",
       "                ('Recall', 0.9754098360655737),\n",
       "                ('AUC', 0.9979879275653923),\n",
       "                ('Log Loss', 0.0764559127800754),\n",
       "                ('MCC', 0.933568045604951),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9787234042553192),\n",
       "                ('Precision', 0.9913793103448276),\n",
       "                ('Recall', 0.9787234042553192),\n",
       "                ('AUC', 0.9903961584633854),\n",
       "                ('Log Loss', 0.09774553003325108),\n",
       "                ('MCC', 0.9443109474170326),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 5.586108922958374},\n",
       " 9: {'id': 9,\n",
       "  'pipeline_name': 'LogisticRegressionPipeline',\n",
       "  'parameters': {'penalty': 'l2',\n",
       "   'C': 8.123565600467177,\n",
       "   'impute_strategy': 'median'},\n",
       "  'score': 0.9748529087969783,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9747899159663865, 0.9754098360655737, 0.9743589743589743],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9747899159663865),\n",
       "                ('Precision', 0.9747899159663865),\n",
       "                ('Recall', 0.9747899159663865),\n",
       "                ('AUC', 0.9886377086045686),\n",
       "                ('Log Loss', 0.19170510282820305),\n",
       "                ('MCC', 0.932536394839626),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9754098360655737),\n",
       "                ('Precision', 0.952),\n",
       "                ('Recall', 0.9754098360655737),\n",
       "                ('AUC', 0.9850869925434962),\n",
       "                ('Log Loss', 0.15159254810085362),\n",
       "                ('MCC', 0.933568045604951),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9743589743589743),\n",
       "                ('Precision', 0.991304347826087),\n",
       "                ('Recall', 0.9743589743589743),\n",
       "                ('AUC', 0.990516206482593),\n",
       "                ('Log Loss', 0.11566930634571038),\n",
       "                ('MCC', 0.9336637889421326),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 5.832842826843262}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
