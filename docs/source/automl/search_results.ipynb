{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring search results\n",
    "\n",
    "After finishing a pipeline search, we can inspect the results. First, let's build a search of 10 different pipelines to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m*****************************\u001b[0m\n",
      "\u001b[1m* Beginning pipeline search *\u001b[0m\n",
      "\u001b[1m*****************************\u001b[0m\n",
      "\n",
      "Optimizing for F1. Greater score is better.\n",
      "\n",
      "Searching up to 5 pipelines. \n",
      "Possible model types: xgboost, linear_model, random_forest\n",
      "\n",
      "✔ XGBoost Classifier w/ One Hot Encod...     0%|          | Elapsed:00:02\n",
      "✔ XGBoost Classifier w/ One Hot Encod...    20%|██        | Elapsed:00:05\n",
      "✔ Random Forest Classifier w/ One Hot...    40%|████      | Elapsed:00:12\n",
      "✔ XGBoost Classifier w/ One Hot Encod...    60%|██████    | Elapsed:00:14\n",
      "✔ Logistic Regression Classifier w/ O...    80%|████████  | Elapsed:00:19\n",
      "✔ Logistic Regression Classifier w/ O...   100%|██████████| Elapsed:00:19\n",
      "\n",
      "✔ Optimization finished\n"
     ]
    }
   ],
   "source": [
    "import evalml\n",
    "\n",
    "X, y = evalml.demos.load_breast_cancer()\n",
    "\n",
    "clf = evalml.AutoClassifier(objective=\"f1\",\n",
    "                            max_pipelines=5)\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Rankings\n",
    "A summary of all the pipelines built can be returned as a dataframe. It is sorted by score. EvalML knows based on your objective function whether or not high or lower is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>score</th>\n",
       "      <th>high_variance_cv</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegressionPipeline</td>\n",
       "      <td>0.973411</td>\n",
       "      <td>False</td>\n",
       "      <td>{'penalty': 'l2', 'C': 8.444214828324364, 'imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>0.970626</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.38438170729269994, 'min_child_weight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RFClassificationPipeline</td>\n",
       "      <td>0.966846</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 569, 'max_depth': 22, 'impute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>0.965192</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.5928446182250184, 'min_child_weight'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>0.952237</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.5288949197529046, 'min_child_weight'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               pipeline_name     score  high_variance_cv  \\\n",
       "0   4  LogisticRegressionPipeline  0.973411             False   \n",
       "1   1             XGBoostPipeline  0.970626             False   \n",
       "2   2    RFClassificationPipeline  0.966846             False   \n",
       "3   0             XGBoostPipeline  0.965192             False   \n",
       "4   3             XGBoostPipeline  0.952237             False   \n",
       "\n",
       "                                          parameters  \n",
       "0  {'penalty': 'l2', 'C': 8.444214828324364, 'imp...  \n",
       "1  {'eta': 0.38438170729269994, 'min_child_weight...  \n",
       "2  {'n_estimators': 569, 'max_depth': 22, 'impute...  \n",
       "3  {'eta': 0.5928446182250184, 'min_child_weight'...  \n",
       "4  {'eta': 0.5288949197529046, 'min_child_weight'...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe Pipeline\n",
    "Each pipeline is given an `id`. We can get more information about any particular pipeline using that id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m********************************************************************************************\u001b[0m\n",
      "\u001b[1m* XGBoost Classifier w/ One Hot Encoder + Simple Imputer + RF Classifier Select From Model *\u001b[0m\n",
      "\u001b[1m********************************************************************************************\u001b[0m\n",
      "\n",
      "Problem Types: Binary Classification, Multiclass Classification\n",
      "Model Type: XGBoost Classifier\n",
      "Objective to Optimize: F1 (greater is better)\n",
      "Number of features: 18\n",
      "\n",
      "Pipeline Steps\n",
      "==============\n",
      "1. One Hot Encoder\n",
      "2. Simple Imputer\n",
      "\t * impute_strategy : most_frequent\n",
      "3. RF Classifier Select From Model\n",
      "\t * percent_features : 0.6273280598181127\n",
      "\t * threshold : -inf\n",
      "4. XGBoost Classifier\n",
      "\t * eta : 0.5928446182250184\n",
      "\t * max_depth : 4\n",
      "\t * min_child_weight : 8.598391737229157\n",
      "\n",
      "Training\n",
      "========\n",
      "Training for Binary Classification problems.\n",
      "Total training time (including CV): 2.5 seconds\n",
      "\n",
      "Cross Validation\n",
      "----------------\n",
      "               F1  Precision  Recall   AUC  Log Loss   MCC # Training # Testing\n",
      "0           0.950      0.935   0.950 0.985     0.154 0.864    379.000   190.000\n",
      "1           0.975      0.959   0.975 0.996     0.102 0.933    379.000   190.000\n",
      "2           0.970      0.991   0.970 0.983     0.137 0.923    380.000   189.000\n",
      "mean        0.965      0.962   0.965 0.988     0.131 0.907          -         -\n",
      "std         0.013      0.028   0.013 0.007     0.026 0.037          -         -\n",
      "coef of var 0.014      0.029   0.014 0.007     0.202 0.041          -         -\n"
     ]
    }
   ],
   "source": [
    "clf.describe_pipeline(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Pipeline\n",
    "You can get the object for any pipeline as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<evalml.pipelines.classification.xgboost.XGBoostPipeline at 0x13ecbfad0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_pipeline(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get best pipeline\n",
    "If you specifically want to get the best pipeline, there is a convenient access. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<evalml.pipelines.classification.logistic_regression.LogisticRegressionPipeline at 0x140e48ed0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importances\n",
    "\n",
    "We can get the feature importances of the resulting pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>0.407441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>0.239457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>0.120609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0.072031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>0.052818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.038344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21</td>\n",
       "      <td>0.028949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>0.003987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25</td>\n",
       "      <td>0.002403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>19</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>29</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance\n",
       "0        22    0.407441\n",
       "1         7    0.239457\n",
       "2        27    0.120609\n",
       "3        20    0.072031\n",
       "4        23    0.052818\n",
       "5         6    0.038344\n",
       "6         1    0.033962\n",
       "7        21    0.028949\n",
       "8         4    0.003987\n",
       "9        25    0.002403\n",
       "10        0    0.000000\n",
       "11        2    0.000000\n",
       "12        3    0.000000\n",
       "13       12    0.000000\n",
       "14       13    0.000000\n",
       "15       18    0.000000\n",
       "16       19    0.000000\n",
       "17       29    0.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = clf.get_pipeline(0)\n",
    "pipeline.feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access raw results\n",
    "You can also get access to all the underlying data like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'id': 0,\n",
       "  'pipeline_name': 'XGBoostPipeline',\n",
       "  'parameters': {'eta': 0.5928446182250184,\n",
       "   'min_child_weight': 8.598391737229157,\n",
       "   'max_depth': 4,\n",
       "   'impute_strategy': 'most_frequent',\n",
       "   'percent_features': 0.6273280598181127},\n",
       "  'score': 0.9651923054186028,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9504132231404958, 0.9752066115702479, 0.9699570815450643],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9504132231404958),\n",
       "                ('Precision', 0.9349593495934959),\n",
       "                ('Recall', 0.9504132231404958),\n",
       "                ('AUC', 0.984731920937389),\n",
       "                ('Log Loss', 0.15365016467281079),\n",
       "                ('MCC', 0.8644170412909863),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9752066115702479),\n",
       "                ('Precision', 0.959349593495935),\n",
       "                ('Recall', 0.9752066115702479),\n",
       "                ('AUC', 0.9960350337318026),\n",
       "                ('Log Loss', 0.10194972637354544),\n",
       "                ('MCC', 0.9327267201397125),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9699570815450643),\n",
       "                ('Precision', 0.9912280701754386),\n",
       "                ('Recall', 0.9699570815450643),\n",
       "                ('AUC', 0.983313325330132),\n",
       "                ('Log Loss', 0.13664108907025327),\n",
       "                ('MCC', 0.9231826763268304),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 2.4699270725250244},\n",
       " 1: {'id': 1,\n",
       "  'pipeline_name': 'XGBoostPipeline',\n",
       "  'parameters': {'eta': 0.38438170729269994,\n",
       "   'min_child_weight': 3.677811458900251,\n",
       "   'max_depth': 13,\n",
       "   'impute_strategy': 'median',\n",
       "   'percent_features': 0.793807787701838},\n",
       "  'score': 0.9706261399583499,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9707112970711297, 0.9709543568464729, 0.9702127659574468],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9707112970711297),\n",
       "                ('Precision', 0.9666666666666667),\n",
       "                ('Recall', 0.9707112970711297),\n",
       "                ('AUC', 0.9917149958574978),\n",
       "                ('Log Loss', 0.11573912199513105),\n",
       "                ('MCC', 0.9211268105467613),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9709543568464729),\n",
       "                ('Precision', 0.9590163934426229),\n",
       "                ('Recall', 0.9709543568464729),\n",
       "                ('AUC', 0.9969227127470707),\n",
       "                ('Log Loss', 0.07704140615686283),\n",
       "                ('MCC', 0.9211492315750531),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9702127659574468),\n",
       "                ('Precision', 0.9827586206896551),\n",
       "                ('Recall', 0.9702127659574468),\n",
       "                ('AUC', 0.9857142857142858),\n",
       "                ('Log Loss', 0.12628072744701058),\n",
       "                ('MCC', 0.9218075091290715),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 2.5258681774139404},\n",
       " 2: {'id': 2,\n",
       "  'pipeline_name': 'RFClassificationPipeline',\n",
       "  'parameters': {'n_estimators': 569,\n",
       "   'max_depth': 22,\n",
       "   'impute_strategy': 'most_frequent',\n",
       "   'percent_features': 0.8593661614465293},\n",
       "  'score': 0.9668456397284798,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9508196721311476, 0.979253112033195, 0.970464135021097],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9508196721311476),\n",
       "                ('Precision', 0.928),\n",
       "                ('Recall', 0.9508196721311476),\n",
       "                ('AUC', 0.9889336016096579),\n",
       "                ('Log Loss', 0.1388421748025717),\n",
       "                ('MCC', 0.8647724688764672),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.979253112033195),\n",
       "                ('Precision', 0.9672131147540983),\n",
       "                ('Recall', 0.979253112033195),\n",
       "                ('AUC', 0.9898804592259438),\n",
       "                ('Log Loss', 0.11232987225229708),\n",
       "                ('MCC', 0.943843520216036),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.970464135021097),\n",
       "                ('Precision', 0.9745762711864406),\n",
       "                ('Recall', 0.970464135021097),\n",
       "                ('AUC', 0.9906362545018007),\n",
       "                ('Log Loss', 0.11575295379524118),\n",
       "                ('MCC', 0.9208800271662652),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 7.544953107833862},\n",
       " 3: {'id': 3,\n",
       "  'pipeline_name': 'XGBoostPipeline',\n",
       "  'parameters': {'eta': 0.5288949197529046,\n",
       "   'min_child_weight': 6.112401049845392,\n",
       "   'max_depth': 6,\n",
       "   'impute_strategy': 'most_frequent',\n",
       "   'percent_features': 0.34402219881309576},\n",
       "  'score': 0.9522372250281359,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9367088607594938, 0.9672131147540983, 0.9527896995708156],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9367088607594938),\n",
       "                ('Precision', 0.940677966101695),\n",
       "                ('Recall', 0.9367088607594938),\n",
       "                ('AUC', 0.9821872410936205),\n",
       "                ('Log Loss', 0.16857726256804248),\n",
       "                ('MCC', 0.8318710075349047),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9672131147540983),\n",
       "                ('Precision', 0.944),\n",
       "                ('Recall', 0.9672131147540983),\n",
       "                ('AUC', 0.9937270682921056),\n",
       "                ('Log Loss', 0.1043367698592575),\n",
       "                ('MCC', 0.9106361866954563),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9527896995708156),\n",
       "                ('Precision', 0.9736842105263158),\n",
       "                ('Recall', 0.9527896995708156),\n",
       "                ('AUC', 0.9845138055222089),\n",
       "                ('Log Loss', 0.14270813298835444),\n",
       "                ('MCC', 0.8783921421654207),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 2.4388489723205566},\n",
       " 4: {'id': 4,\n",
       "  'pipeline_name': 'LogisticRegressionPipeline',\n",
       "  'parameters': {'penalty': 'l2',\n",
       "   'C': 8.444214828324364,\n",
       "   'impute_strategy': 'most_frequent'},\n",
       "  'score': 0.9734109818152151,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.970464135021097, 0.9754098360655737, 0.9743589743589743],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.970464135021097),\n",
       "                ('Precision', 0.9745762711864406),\n",
       "                ('Recall', 0.970464135021097),\n",
       "                ('AUC', 0.9885193514025328),\n",
       "                ('Log Loss', 0.1943294590819038),\n",
       "                ('MCC', 0.9215733295732883),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9754098360655737),\n",
       "                ('Precision', 0.952),\n",
       "                ('Recall', 0.9754098360655737),\n",
       "                ('AUC', 0.9849686353414605),\n",
       "                ('Log Loss', 0.1533799764176819),\n",
       "                ('MCC', 0.933568045604951),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9743589743589743),\n",
       "                ('Precision', 0.991304347826087),\n",
       "                ('Recall', 0.9743589743589743),\n",
       "                ('AUC', 0.990516206482593),\n",
       "                ('Log Loss', 0.1164316714613053),\n",
       "                ('MCC', 0.9336637889421326),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 4.601983070373535}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
