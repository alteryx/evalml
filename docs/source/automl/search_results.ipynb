{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring search results\n",
    "\n",
    "After finishing a pipeline search, we can inspect the results. First, let's build a search of 10 different pipelines to explore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m*****************************\u001b[0m\n",
      "\u001b[1m* Beginning pipeline search *\u001b[0m\n",
      "\u001b[1m*****************************\u001b[0m\n",
      "\n",
      "Optimizing for F1. Greater score is better.\n",
      "\n",
      "Searching up to 10 pipelines. No time limit is set. Set one using max_time parameter.\n",
      "\n",
      "Possible model types: linear_model, random_forest, xgboost\n",
      "\n",
      "✔ XGBoost w/ imputation:                     0%|          | Elapsed:00:00\n",
      "✔ XGBoost w/ imputation:                    10%|█         | Elapsed:00:00\n",
      "✔ Random Forest w/ imputation:              20%|██        | Elapsed:00:06\n",
      "✔ XGBoost w/ imputation:                    30%|███       | Elapsed:00:06\n",
      "✔ LogisticRegression w/ imputation + ...    40%|████      | Elapsed:00:10\n",
      "✔ XGBoost w/ imputation:                    50%|█████     | Elapsed:00:10\n",
      "✔ LogisticRegression w/ imputation + ...    60%|██████    | Elapsed:00:14\n",
      "✔ XGBoost w/ imputation:                    70%|███████   | Elapsed:00:14\n",
      "✔ LogisticRegression w/ imputation + ...    80%|████████  | Elapsed:00:18\n",
      "✔ LogisticRegression w/ imputation + ...    90%|█████████ | Elapsed:00:22\n",
      "✔ LogisticRegression w/ imputation + ...   100%|██████████| Elapsed:00:22\n",
      "\n",
      "✔ Optimization finished\n"
     ]
    }
   ],
   "source": [
    "import evalml\n",
    "\n",
    "X, y = evalml.demos.load_breast_cancer()\n",
    "\n",
    "clf = evalml.AutoClassifier(objective=\"f1\",\n",
    "                            max_pipelines=10)\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Rankings\n",
    "A summary of all the pipelines built can be returned as a dataframe. It is sorted by score. EvalML knows based on your objective function whether or not high or lower is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>score</th>\n",
       "      <th>high_variance_cv</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegressionPipeline</td>\n",
       "      <td>0.980527</td>\n",
       "      <td>False</td>\n",
       "      <td>{'penalty': 'l2', 'C': 0.5765626434012575, 'im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegressionPipeline</td>\n",
       "      <td>0.974853</td>\n",
       "      <td>False</td>\n",
       "      <td>{'penalty': 'l2', 'C': 6.239401330891865, 'imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegressionPipeline</td>\n",
       "      <td>0.974853</td>\n",
       "      <td>False</td>\n",
       "      <td>{'penalty': 'l2', 'C': 8.123565600467177, 'imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegressionPipeline</td>\n",
       "      <td>0.973411</td>\n",
       "      <td>False</td>\n",
       "      <td>{'penalty': 'l2', 'C': 8.444214828324364, 'imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>0.970674</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.38438170729269994, 'min_child_weight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>0.969254</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.6481718720511973, 'min_child_weight'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>RFClassificationPipeline</td>\n",
       "      <td>0.966846</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 569, 'max_depth': 22, 'impute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>0.965195</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.5928446182250184, 'min_child_weight'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>0.965195</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.9786183422327642, 'min_child_weight'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>0.960739</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.5288949197529046, 'min_child_weight'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               pipeline_name     score  high_variance_cv  \\\n",
       "0   8  LogisticRegressionPipeline  0.980527             False   \n",
       "1   6  LogisticRegressionPipeline  0.974853             False   \n",
       "2   9  LogisticRegressionPipeline  0.974853             False   \n",
       "3   4  LogisticRegressionPipeline  0.973411             False   \n",
       "4   1             XGBoostPipeline  0.970674             False   \n",
       "5   5             XGBoostPipeline  0.969254             False   \n",
       "6   2    RFClassificationPipeline  0.966846             False   \n",
       "7   0             XGBoostPipeline  0.965195             False   \n",
       "8   7             XGBoostPipeline  0.965195             False   \n",
       "9   3             XGBoostPipeline  0.960739             False   \n",
       "\n",
       "                                          parameters  \n",
       "0  {'penalty': 'l2', 'C': 0.5765626434012575, 'im...  \n",
       "1  {'penalty': 'l2', 'C': 6.239401330891865, 'imp...  \n",
       "2  {'penalty': 'l2', 'C': 8.123565600467177, 'imp...  \n",
       "3  {'penalty': 'l2', 'C': 8.444214828324364, 'imp...  \n",
       "4  {'eta': 0.38438170729269994, 'min_child_weight...  \n",
       "5  {'eta': 0.6481718720511973, 'min_child_weight'...  \n",
       "6  {'n_estimators': 569, 'max_depth': 22, 'impute...  \n",
       "7  {'eta': 0.5928446182250184, 'min_child_weight'...  \n",
       "8  {'eta': 0.9786183422327642, 'min_child_weight'...  \n",
       "9  {'eta': 0.5288949197529046, 'min_child_weight'...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe Pipeline\n",
    "Each pipeline is given an `id`. We can get more information about any particular pipeline using that id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m************************\u001b[0m\n",
      "\u001b[1m* Pipeline Description *\u001b[0m\n",
      "\u001b[1m************************\u001b[0m\n",
      "\n",
      "Pipeline Name: XGBoost w/ imputation\n",
      "Model type: ModelTypes.XGBOOST\n",
      "Objective: F1 (greater is better)\n",
      "Total training time (including CV): 0.2 seconds\n",
      "\n",
      "Parameters\n",
      "==========\n",
      "• eta: 0.5928446182250184\n",
      "• min_child_weight: 8.598391737229157\n",
      "• max_depth: 4\n",
      "• impute_strategy: most_frequent\n",
      "• percent_features: 0.6273280598181127\n",
      "\n",
      "Cross Validation\n",
      "=================\n",
      "               F1  Precision  Recall   AUC  Log Loss   MCC # Training # Testing\n",
      "0           0.959      0.943   0.959 0.987     0.150 0.887    379.000   190.000\n",
      "1           0.975      0.959   0.975 0.996     0.106 0.933    379.000   190.000\n",
      "2           0.962      0.974   0.962 0.983     0.134 0.899    380.000   189.000\n",
      "mean        0.965      0.959   0.965 0.988     0.130 0.906          -         -\n",
      "std         0.009      0.016   0.009 0.006     0.022 0.024          -         -\n",
      "coef of var 0.009      0.016   0.009 0.007     0.172 0.026          -         -\n"
     ]
    }
   ],
   "source": [
    "clf.describe_pipeline(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Pipeline\n",
    "You can get the object for any pipeline as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<evalml.pipelines.classification.xgboost.XGBoostPipeline at 0x1305fbd50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_pipeline(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get best pipeline\n",
    "If you specifically want to get the best pipeline, there is a convenient access. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<evalml.pipelines.classification.logistic_regression.LogisticRegressionPipeline at 0x1327860d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importances\n",
    "\n",
    "We can get the feature importances of the resulting pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.371201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.153827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.145848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>0.087861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>0.052571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>0.044619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.036699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0.032339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.026583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>24</td>\n",
       "      <td>0.026560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>0.021891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance\n",
       "0        22    0.371201\n",
       "1        27    0.153827\n",
       "2         7    0.145848\n",
       "3        20    0.087861\n",
       "4        23    0.052571\n",
       "5        26    0.044619\n",
       "6         6    0.036699\n",
       "7        13    0.032339\n",
       "8         1    0.026583\n",
       "9        24    0.026560\n",
       "10       21    0.021891\n",
       "11        0    0.000000\n",
       "12        2    0.000000\n",
       "13        3    0.000000\n",
       "14        4    0.000000\n",
       "15        5    0.000000\n",
       "16        8    0.000000\n",
       "17        9    0.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = clf.get_pipeline(0)\n",
    "pipeline.feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the feature importances as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEZCAYAAACNebLAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3debgdVZnv8e+PMAQZA4koGUiAiAaRgIcAKoKKEKQFrmILtHTgoqiIILTdxsbLEFsZbFBbQEgLKtAYEa7duRjmSRyAhBATAkRCDCQRIRLmOeG9f6x1sNipc07tk11n4vd5nnp21VpVa79Vu3a9u4ZdpYjAzMys0Vq9HYCZmfVNThBmZlbKCcLMzEo5QZiZWSknCDMzK+UEYWZmpZwgMknXSJrUgnaOkPSbwvBzkrZe03ZtzUj6V0k/6u04ukPSqLweDertWOzN5U2VICQtlvRi/rI9JuknkjYEiIj9IuKnrX7PiNgwIha1ul1Jt0raK/efLen6hvrvSbq6MLyRpHPyMnhe0iOSrpS0a2GcyHXPSfqrpJ9J2rTVsTfEuVjS3i1s70JJRzeWR8S3I+KzrXqfJuIZnZfr2k1M84ZlEhGP5PVoVQviWSxpdAd1t0p6KX/+7d3ua/h+Tc//mpJ0qqTLeur9OtP4g7G/eVMliOzjEbEhsDPQBnyjl+Nphf8DbC3pSID8pZ4EfCEPrwfcDOwA/B2wMfAuYBqwX0NbO+blszUwBDi1B+Jvpf2AGb0dRD92bE5G7d3vezMYJf1yO9WTSbE2EfGm6YDFwN6F4e8AV+f+W4HP5v4jgN8C5wJPAw8AHylMtwlwEfAosAz4N2BQYdrfFMYNYNvc/xPgPOBXwLPAncA2hXHfCdwArAAWAH/fybzcCuxVGP4Q8ASwFXA/8PlC3WdzrBt0sXxejzUPHwNcXxjeEpie41sIfK5Qtx7wPeDPufsesF6uGwpcDTyVp72d9OPkUuA14EXgOeBfSmK6Dfhk7n9/jnH/PPwRYE5h3PcAczuYt1OBy3L/6NzOkcAS4ElSMt0FmJvjPLcwbVfrw2LeuF4V3+uR/F7P5W53YBtSwn4C+CvwX8CmefzVlkkh3rUrfA6nAlcAl5DWsflAW0OsoztZpz7bQV2H6yawP3AP8ExenqcW6srm//Xl0/B5rF2I41t5mb8IbEsn37nOPuvCen0M8GBeJt/Mn8HvcsxXAOvmcfcClgL/mj+bxcA/NHz3LwGWAw+TfmCu1bCefDd/tlcBLwGr8rw/VWF5tS+LSXnZ/RU4qVA/KMf2UJ6Xu4GRzW4/Km8z17SB/tRR+CIDI/OX55uNX478Qa8ETgDWAT5N2jBslut/CVwIbAC8FbiLvEGm6wTxBDABWJu0YZiW6zbIK8uRuW6nvHKMa2L+LszT3AKoUD4N+EmF6YuxDgGuB6YU6n8NnA8MBsbnL8mHc90U4I68PIaRvnzty/Z04IK8LNcB9miPj4aNa0lMU4Af5P72L8aZhbrvF8adDJzeQTunsnqCuCDPyz6kL/J/5/iHA48De1ZcH94wDx2819qF+m2Bj5KS6rC8XL9Xtp6WtdHF53BqnpePkTYmpwN3VFx/bqUkQdDFuknaqO5ASvrvAR4DDupk/l9fPh3M362kjeP2+f3WoZPvXGefdWG9/h/SnvP2wMvATaS95E2A+4BJhXlZCZyTP589geeB7XL9JbmtjXLcfwSOalhPvpzjXp+G7UETy+s/8/Q75njflev/GZgHbAco12/e1WfU7W3mmkzc3zrSF+850i/Eh0lfsvUbvxz5Q/0zb9zI3gUcDmyRP7D1C3WHArcUpu0sQfyoUPcx4IHc/2ng9oZ4LwROaWL+PpPf73MN5TcCZxSGx+dl8AywoCHWZ3LdKtIv5eG5bmQu26gw/unkxEPacH+sULcvsDj3T8lfqm1LYl5M5wniI+S9AuBa0t7QHXn4NuAThXFvB/booJ1TWX2jPbxQ/wTw6cLwVcBXulofyuahg/dau5N5PAi4p6NlUmyjwudwKnBjoW4c8GLF9edW4IX8+T8FzO7Ouknae/xuR/NPtQRR/GHS6Xeus8+6sF6/vzB8N/C1wvDZ5ATN3xLEBoX6K0iHcQcBr1DY6AKfB24trCePNMRyBA0JouLyGtGwrh2S+xcAB5a0scbbj7KuXx7bW0MHRcSmEbFVRBwTES92MN6yyEs5e5i0a78V6RfNo5KekvQU6YN4a8X3/0uh/wVgw9y/FbBre5u53X8A3lalUUmbA/9OWtmmNJxcfgJ4e/tARMyJiE2BT5B+JRXtnOsGAz8Ebpc0mDTvKyLi2cK4D5N+bZPrH26o2zL3f4d0KOR6SYskTa4yT9nvgXdI2oKU2C4BRkoaStoT+3We/01Ju9i/a6Ltxwr9L5YMb1gY7mh9aJqkLSRNk7RM0jPAZaTDcFV09TnA6uvY4CaOhx+Xvx+bRsTOuazTdVPSrpJukbRc0tOkw3VV56cjSwr9a/qdg+Y+6ycj4vnCcPtnPTTH0bieF5d9Me5SFZdXR9uJkaQfY43WaPvRkTdjgqhquCQVhkeRfkUuIf2aGVr4Im0cEduv4fstAW4rtLlppJOEX6w4/feAayPiBNJG898LdTcB+0jaoGowEfEq8CNgDPBu0rxvJmmjwmijSMeDyfVbNdT9Obf1bET8U0RsDRwAnCjpI+1v1UUcL5B+8R0P3BsRr5CSwInAQxHx1zzqvsDN0YIrfTrQ0foA6RDEWwp1xS9l2fx9O5fvEBEbk/b81MU07br6HOrQ1bp5OemcyMiI2IR06K59fsrmpbPl1a44XV3fuY4MafiutH/WfwVeZfX1vLjsG+e3bP47W15dWUI6f1JWvibbj1JOEB17K3CcpHUkfYp01c+MiHiUdGz+bEkbS1pL0jaS9lzD97ua9Ev58Pye60jaRdK7uppQ0sdIx7RPzEVfBg6S9KE8fAnp5N4vJb1b0qC8V9DWSZuDSMczXwQWRcQS0ob5dEmDJb0HOIr06xfgZ8A3JA3Lv+5Pbq+T9HeSts0b2KdJh0hey9M9RjoW3JnbgGPzK6RDEMVhSIfrftVFO2uidH3IdXOAQ3JdG3BwYbrlpHktzuNGpEOdT0saTjquXNThMqnwOdShq3VzI9JezUuSJgCHFaYtm/85wAeV/t+xCfD1zt68xu9cZ06TtK6kPUhX/v0i//i4AviW0mXjW5G+c50t+8eAEZLWLZR1try68iPgm5LG5iu83pOPHnR7+9EZJ4iO3QmMJf1q+BZwcEQ8kev+EViXdHLrSeBKCodwuiMfMtgHOIT0a+UvwJmsfgjoDfIvyQtIhwZW5LYeB/4JmCpp/Yh4iXSV032kjegzpGOZuwB/39DkHyQ9l+drEvC/2tslHfcdneP7Jen45o257t+AWaSrgOYBs3MZpOV4I2mj+Hvg/Ii4JdedTkosT0n6agezeRvpS/XrsuGcePYlnaOoS2frw/8h/ap7EjiN9AsReH0P6FvAb/M87pbH2ZmULH8F/N+G9+pqmXT2ObRchXXzGNJhzWdJPwyuKEy72vxHxA3Az0nryt2kjVtXWv6d68Rf8nv8mXQhyRci4oFc92XSHtAi4Dekz/riTtq6mXQxzF8kte/tdri8Kjgnj3896Xt8EencTLe2H11pv5LECiQdQTph/YHejsW6ln+FnRsRE2pq/wi8PrwpKP359LKIGNHbsfQF3oOwgeKU3g7AbKDp///0sze9iLirt2MwG4h8iMnMzEr5EJOZmZVygjAzs1ID5hzE0KFDY/To0b0dhplZv3L33Xf/NSKGldUNmAQxevRoZs2a1dthmJn1K5Ie7qjOh5jMzKyUE4SZmZVygjAzs1JOEGZmVsoJwszMSjlBmJlZKScIMzMr5QRhZmalBswf5cqMntz1A8YWn7F/D0RiZtb/eA/CzMxKOUGYmVkpJwgzMyvlBGFmZqWcIMzMrJQThJmZlXKCMDOzUrUmCEkTJS2QtFDS5JL6L0iaJ2mOpN9IGpfLR0t6MZfPkXRBnXGamdnqavujnKRBwHnAR4GlwExJ0yPivsJol0fEBXn8A4BzgIm57qGIGF9XfGZm1rk69yAmAAsjYlFEvAJMAw4sjhARzxQGNwCixnjMzKwJdSaI4cCSwvDSXPYGkr4k6SHgLOC4QtUYSfdIuk3SHjXGaWZmJXr9JHVEnBcR2wBfA76Rix8FRkXETsCJwOWSNm6cVtLRkmZJmrV8+fKeC9rM7E2gzgSxDBhZGB6RyzoyDTgIICJejogncv/dwEPAOxoniIipEdEWEW3Dhg1rWeBmZlZvgpgJjJU0RtK6wCHA9OIIksYWBvcHHszlw/JJbiRtDYwFFtUYq5mZNajtKqaIWCnpWOA6YBBwcUTMlzQFmBUR04FjJe0NvAo8CUzKk38QmCLpVeA14AsRsaKuWM3MbHW1Pg8iImYAMxrKTi70H9/BdFcBV9UZm5mZda7XT1KbmVnf5ARhZmalnCDMzKyUE4SZmZVygjAzs1JOEGZmVsoJwszMSjlBmJlZKScIMzMr5QRhZmalnCDMzKyUE4SZmZVygjAzs1JOEGZmVsoJwszMSjlBmJlZKScIMzMr5QRhZmalnCDMzKxUrQlC0kRJCyQtlDS5pP4LkuZJmiPpN5LGFeq+nqdbIGnfOuM0M7PV1ZYgJA0CzgP2A8YBhxYTQHZ5ROwQEeOBs4Bz8rTjgEOA7YGJwPm5PTMz6yF17kFMABZGxKKIeAWYBhxYHCEinikMbgBE7j8QmBYRL0fEn4CFuT0zM+sha9fY9nBgSWF4KbBr40iSvgScCKwLfLgw7R0N0w6vJ0wzMyvT6yepI+K8iNgG+BrwjWamlXS0pFmSZi1fvryeAM3M3qTqTBDLgJGF4RG5rCPTgIOamTYipkZEW0S0DRs2bA3DNTOzojoTxExgrKQxktYlnXSeXhxB0tjC4P7Ag7l/OnCIpPUkjQHGAnfVGKuZmTWo7RxERKyUdCxwHTAIuDgi5kuaAsyKiOnAsZL2Bl4FngQm5WnnS7oCuA9YCXwpIlbVFauZma2uzpPURMQMYEZD2cmF/uM7mfZbwLfqi87MzDrT6yepzcysb3KCMDOzUk4QZmZWygnCzMxKOUGYmVkpJwgzMyvlBGFmZqW6TBCStpB0kaRr8vA4SUfVH5qZmfWmKnsQPyH9G3rLPPxH4Ct1BWRmZn1DlQQxNCKuAF6DdAsNwLe9MDMb4KokiOclbU5+mI+k3YCna43KzMx6XZV7MZ1IurvqNpJ+CwwDDq41KjMz63VdJoiImC1pT2A7QMCCiHi19sjMzKxXVbmK6UvAhhExPyLuBTaUdEz9oZmZWW+qcg7icxHxVPtARDwJfK6+kMzMrC+okiAGSVL7gKRBwLr1hWRmZn1BlZPU1wI/l3RhHv58LjMzswGsSoL4GikpfDEP3wD8qLaIzMysT6hyFdNrwA9zZ2ZmbxJVrmJ6v6QbJP1R0iJJf5K0qErjkiZKWiBpoaTJJfUnSrpP0lxJN0naqlC3StKc3E1vbrbMzGxNVTnEdBFwAnA3TdxiI5/MPg/4KLAUmClpekTcVxjtHqAtIl6Q9EXgLODTue7FiBhf9f3MzKy1qiSIpyPimm60PQFYGBGLACRNAw4EXk8QEXFLYfw7gM90433MzKwGVS5zvUXSdyTtLmnn9q7CdMOBJYXhpbmsI0cBxUQ0WNIsSXdIOqjC+5mZWQtV2YPYNb+2FcoC+HCrgpD0mdz+noXirSJimaStgZslzYuIhxqmOxo4GmDUqFGtCsfMzKh2FdOHutn2MmBkYXhELnsDSXsDJwF7RsTLhfddll8XSboV2Al4Q4KIiKnAVIC2trboZpxmZlaiyh4EkvYHtgcGt5dFxJQuJpsJjJU0hpQYDgEOa2h3J+BCYGJEPF4oHwK8EBEvSxoKvJ90AtvMzHpIlwlC0gXAW4APkf4gdzBwV1fTRcRKSceSnkY3CLg4IuZLmgLMiojpwHeADYFf5Lt5PBIRBwDvAi6U9BrpPMkZDVc/mZlZzarsQbwvIt4jaW5EnCbpbN54MrlDETEDmNFQdnKhf+8OpvsdsEOV9zAzs3pUuYrpxfz6gqQtgVeBt9cXkpmZ9QVV9iCulrQp6XDQbNIVTL4Xk5nZAFclQZyVry66StLVpBPVL9UblpmZ9bYqh5h+394TES9HxNPFMjMzG5g63IOQ9DbSP5/Xz5ejtj80aGPSVU1mZjaAdXaIaV/gCNIf3M7mbwniGeBf6w3LzMx6W4cJIiJ+KulS4NCI+K8ejMnMzPqATs9B5IcFndBDsZiZWR9S5ST1jZK+KmmkpM3au9ojMzOzXlXlMtf2B/h8qVAWwNatD8fMzPqKKndzHdMTgZiZWd9S5WZ96wBfBD6Yi24FLoyIV2uMy8zMelmVQ0w/BNYBzs/Dh+eyz9YVlJmZ9b4qCWKXiNixMHyzpD/UFZCZmfUNVa5iWiVpm/aB/AjQVfWFZGZmfUGVPYh/Bm6RtIj0b+qtgCNrjcrMzHpdlauYbpI0FtguFy0oPjvazMwGpipXMQ0GjgE+QPr/w+2SLogI3/LbzGwAq3KI6RLgWeAHefgw4FLgU3UFZWZmva/KSep3R8RREXFL7j4HbF+lcUkTJS2QtFDS5JL6EyXdJ2mupJskbVWomyTpwdxNqj5LZmbWClUSxGxJu7UPSNoVmNXVRJIGAecB+wHjgEMljWsY7R6gLSLeA1wJnJWn3Qw4BdgVmACcImlIhVjNzKxFqiSI9wK/k7RY0mLS0+R2kTRP0txOppsALIyIRRHxCjANOLA4Qt4jeSEP3kF69gSkZ1HcEBErIuJJ4AZgYuW5MjOzNVblHER3N8zDgSWF4aWkPYKOHAVc08m0wxsnkHQ0cDTAqFGjuhmmmZmVqXKZ68P58M7I4vgRMbtVQUj6DNAG7NnMdBExFZgK0NbWFq2Kx8zMql3m+k3So0cfIl3mSn79cBeTLiMllXYjcllj+3sDJwF7Fv5fsQzYq2HaW7uK1czMWqfKIaa/B7bJ5xGaMRMYK2kMaYN/COkS2ddJ2gm4EJgYEY8Xqq4Dvl04Mb0P8PUm39/MzNZAlQRxL7Ap8HhXIxZFxEpJx5I29oOAiyNivqQpwKyImA58B9gQ+IUkgEci4oCIWJH3XGbm5qZExIpm3t/MzNZMlQRxOnCPpHuB12+xEREHdDVhRMwAZjSUnVzo37uTaS8GLq4Qn5mZ1aBKgvgpcCYwD3it3nDMzKyvqJIgXoiI/6g9EjMz61OqJIjbJZ0OTOeNh5hadpmrmZn1PVUSxE75dbdCWZXLXM3MrB+r8ke5D/VEIGZm1rd0mCAkfSYiLpN0Yll9RJxTX1hmZtbbOtuD2CC/btQTgZiZWd/SYYKIiAvz62k9F46ZmfUVVW73bWZmb0JOEGZmVsoJwszMSnWZICRtIekiSdfk4XGSjqo/NDMz601V9iB+Qroj65Z5+I/AV+oKyMzM+oYqCWJoRFxBvlFfRKwEVtUalZmZ9boqCeJ5SZuTnyYnaTfg6VqjMjOzXlflXkwnkm7Ut42k3wLDgINrjcrMzHpdpwlC0lrAYGBPYDtAwIKIeLUHYjMzs17UaYKIiNcknRcROwHzeygmMzPrA6qcg7hJ0ieVHxptZmZvDlUSxOeBXwAvS3pG0rOSnqnSuKSJkhZIWihpckn9ByXNlrRS0sENdaskzcnd9EpzY2ZmLVPleRDdupurpEHAecBHgaXATEnTI+K+wmiPAEcAXy1p4sWIGN+d967D6Mm/6nKcxWfs3wORmJn1jC4ThKQPlpVHxK+7mHQCsDAiFuV2pgEHAq8niIhYnOteqxivmZn1kCqXuf5zoX8wacN/N10/cnQ4sKQwvBTYtYnYBkuaBawEzoiI/24cQdLRwNEAo0aNaqJpMzPrSpVDTB8vDksaCXyvtoj+ZquIWCZpa+BmSfMi4qGG2KYCUwHa2tqiB2IyM3vT6M7dXJcC76ow3jJgZGF4RC6rJCKW5ddFwK3ATtVDNDOzNVXlHMQPyLfZICWU8cDsCm3PBMZKGkNKDIcAh1UJStIQ4IWIeFnSUOD9wFlVpu3rqpzsBp/wNrPeV+UcxKxC/0rgZxHx264mioiVko4l3Ql2EHBxRMyXNAWYFRHTJe0C/BIYAnxc0mkRsT1pD+XCfPJ6LdI5iPs6eCszM6tBlQSxaUR8v1gg6fjGsjIRMQOY0VB2cqF/JunQU+N0vwN2qBCbmZnVpMo5iEklZUe0OA4zM+tjOtyDkHQo6ZzBmIZ/Mm8ErKg7MDMz612dHWL6HfAoMBQ4u1D+LDC3zqDMzKz3dZggIuJh4GFg954Lx8zM+oouz0FI2k3STEnPSXol30Sv0s36zMys/6pykvpc4FDgQWB94LOkm/CZmdkAVumf1BGxEBgUEasi4sfAxHrDMjOz3lblfxAvSFoXmCPpLNKJ6+7cosPMzPqRKhv6w/N4xwLPk+6v9Mk6gzIzs95X5W6uD0taH3h7RJzWAzGZmVkfUOUqpo8Dc4Br8/B4PwLUzGzgq3KI6VTSQ4KeAoiIOcCYGmMyM7M+oEqCeDUinm4o88N5zMwGuCpXMc2XdBgwSNJY4DjSbTjMzGwAq7IH8WVge+Bl4HLgaeArdQZlZma9r7O7uV4aEYcDn4uIk4CTei4sMzPrbZ3tQbxX0pbA/5Y0RNJmxa6nAjQzs97R2TmIC4CbgK2BuwEV6iKXm5nZANXhHkRE/EdEvIv0LOmtI2JMoXNyMDMb4Lo8SR0RX+xu45ImSlogaaGkySX1H5Q0W9JKSQc31E2S9GDuyh57amZmNartpnuSBpFuC74fMA44VNK4htEeIT3f+vKGaTcDTgF2Jf1J7xRJQ+qK1czMVlfnXVknAAsjYlFEvAJMAw4sjhARiyNiLvBaw7T7AjdExIqIeBK4Ad9i3MysR9WZIIYDSwrDS3NZy6aVdLSkWZJmLV++vNuBmpnZ6vr1cx0iYmpEtEVE27Bhw3o7HDOzAaXOBLGM9OyIdiNyWd3TmplZC9SZIGYCYyWNyU+kOwSoepvw64B98h/0hgD75DIzM+shtSWIiFhJegrddcD9wBURMV/SFEkHAEjaRdJS4FPAhZLm52lXAN8kJZmZwJRcZmZmPaTK3Vy7LSJmADMayk4u9M8kHT4qm/Zi4OI64zMzs47165PUZmZWn1r3IKxeoyf/qstxFp+xfw9EYmYDkfcgzMyslBOEmZmVcoIwM7NSThBmZlbKCcLMzEo5QZiZWSknCDMzK+UEYWZmpZwgzMyslBOEmZmVcoIwM7NSThBmZlbKCcLMzEo5QZiZWSknCDMzK+UEYWZmpZwgzMysVK0JQtJESQskLZQ0uaR+PUk/z/V3Shqdy0dLelHSnNxdUGecZma2utoeOSppEHAe8FFgKTBT0vSIuK8w2lHAkxGxraRDgDOBT+e6hyJifF3xmZlZ5+p8JvUEYGFELAKQNA04ECgmiAOBU3P/lcC5klRjTNYBP9/azBrVeYhpOLCkMLw0l5WOExErgaeBzXPdGEn3SLpN0h5lbyDpaEmzJM1avnx5a6M3M3uT66snqR8FRkXETsCJwOWSNm4cKSKmRkRbRLQNGzasx4M0MxvI6kwQy4CRheERuax0HElrA5sAT0TEyxHxBEBE3A08BLyjxljNzKxBnecgZgJjJY0hJYJDgMMaxpkOTAJ+DxwM3BwRIWkYsCIiVknaGhgLLKoxVmsRn8swGzhqSxARsVLSscB1wCDg4oiYL2kKMCsipgMXAZdKWgisICURgA8CUyS9CrwGfCEiVtQVq5mZra7OPQgiYgYwo6Hs5EL/S8CnSqa7CriqztjMzKxzffUktZmZ9TInCDMzK1XrISazNeET3ma9y3sQZmZWynsQNuBV2RMB742YNfIehJmZlXKCMDOzUj7EZNaEVp0492Ev6w+8B2FmZqWcIMzMrJQPMZn1c/6/iNXFexBmZlbKCcLMzEo5QZiZWSknCDMzK+UEYWZmpZwgzMyslBOEmZmVcoIwM7NStSYISRMlLZC0UNLkkvr1JP08198paXSh7uu5fIGkfeuM08zMVldbgpA0CDgP2A8YBxwqaVzDaEcBT0bEtsB3gTPztOOAQ4DtgYnA+bk9MzPrIXXuQUwAFkbEooh4BZgGHNgwzoHAT3P/lcBHJCmXT4uIlyPiT8DC3J6ZmfUQRUQ9DUsHAxMj4rN5+HBg14g4tjDOvXmcpXn4IWBX4FTgjoi4LJdfBFwTEVc2vMfRwNF5cDtgQYXQhgJ/XYNZa3U7fbUtx9TzbTmmnm/LMcFWETGsrKJf36wvIqYCU5uZRtKsiGhb0/duVTt9tS3H1PNtOaaeb8sxda7OQ0zLgJGF4RG5rHQcSWsDmwBPVJzWzMxqVGeCmAmMlTRG0rqkk87TG8aZDkzK/QcDN0c65jUdOCRf5TQGGAvcVWOsZmbWoLZDTBGxUtKxwHXAIODiiJgvaQowKyKmAxcBl0paCKwgJRHyeFcA9wErgS9FxKoWhdbUIakeaKevtuWYer4tx9TzbTmmTtR2ktrMzPo3/5PazMxKOUGYmVkpJwgzMyvVr/8H0R9JOg74ZUQs6e1YeoKkzSPiiW5Mtytwf0Q8I2l9YDKwM+nChW9HxNMtDrXXSXprRDzeyzG8k3Qng+G5aBkwPSLu72Zbw4E7I+K5QvnEiLi2iXYmABERM/NteCYCD0TEjGZjKmn7koj4xxa08wHS3R7ujYjrm5iu/QrPP0fEjZIOA94H3A9MjYhXm4xja+ATpL8JrAL+CFweEc800067Ab0HIWljSadLujQv+GLd+U20M1vSNyRt04KwvgncKel2ScdIKv0HY4WYNpF0hqQHJK2Q9ISk+3PZpk229TZJP5R0nqTNJZ0qaZ6kKyS9vYl2zpA0NPe3SVpEmteHJe3Z5CxeDLyQ+79P+o/Mmbnsx0221SMkHdnEuJs1dJsDd0kaImmzFsVzTZPjf410SxyRLiu/K/f/rOxmm120dRzwP8CXgXslFW+z8+0m2jkF+A/gh5JOB84FNgAmSzqpyZimN3T/D/hE+3CTbd1V6P9cjmsj4JQml9WPgf2B4yVdCnwKuBPYBfhRkzEdB1wADM7Tr0dKFJE+wgEAAAafSURBVHdI2quZtl4XEQO2A64CzgAOIv234ipgvVw3u4l2/gT8O/AI6UtzArBlN2O6h5SY9yFd5rscuJb0f5CNmmjnOuBrwNsKZW/LZdc3GdO1pC/yZGBubmNkLvufJtqZV+i/Bdgl97+DdGlzMzHdX+if3VA3p8m23gb8kHTzyM1Jt3KZB1wBvL2F69sjTYz7Wl6vit2r+XVRE+3s3EH3XuDRJuP/I7BOSfm6wINNtjUP2DD3jwZmAcfn4XuabGcQ8BbgGWDjXL4+MLfJmGYDlwF7AXvm10dz/55NtnVPoX8mMCz3b1D8HlRoZ25+XRt4DBiUh9WN+ZtXmP4twK25f1Qzy/wNbXZnov7SNW5IgJOA3+aNRDMJYnahfw/gfOAveSN4dJMxNW7s1gEOAH4GLG+inQXdqetg/OLK/khDXeWNMWm3eO3cf0dDXeUvTR7/F8CRuf/HQFvufwcws8m2WpIAc1tzO+jmAS830c4/5bh2KJT9qZlY8jSrgJvzutjYvdhkWw+Q7svTWL5VN9ap+Q3DG+b5PafJdeqesv5m1808/lqkH3c3AONzWeVk3NDWH4AheVsyq6GumQR4LykBDwGeBTbL5YMp/Eiq2NY8/vYDeEgxLtKhr+bnszsT9Zcub7DWaig7ApgPPNxEO6slE9KvmonAj5uMqcOVB3hLE+1cD/wLsEWhbIu88buxyZj+UOj/t4a6Zn4NfTnH9WHSr/Tvk36dnQZc2mRMmwA/AR4i7XK/CiwCbgN27O4yZw0SYB7/MWB83mgWu9Gk48jNtDWClAjPIR2eaHpjlTcwYzuoW9JkWxNJd06+hvQHq6l5o76QdFPNZtq6uX0jXChbG7gEWNVEO3e2fy+K3+W8flT+kdfBcj+3cX1ooo3FeX38U359ey7fsJl1ipSwFgEPA8cBNwH/SdrYn9JkTMeTfqz8JynZt//AGgb8ulvz2Z2J+ksHnAXsXVI+kSZ2mUm3Hm9VTO9oUTtDSMfkHwCeJP0T/f5ctlmTbU0hHw5oKN8WuLLJtvYCfk46lDYPmEG64+5qhy4qtrcxsCPpkMkW3WyjJQkwj38R8IEO6i7vZnwHAHcAf+nGtAcD23VQd1A32lsL2A34ZO52Ix+2aLKdERQOfzbUvb+JdtbroHwohb2vbi73/UkXPHS7jZI23wKMaXKaLcmHrIFN82c6oZvvv32e/p2tmJ8B/0/qTq6k2C8iKp/Ea9UVGa2UYxpBOpyzRjG18IqTvricpgBnFePJ5dsCZ0TEwb0U1+vLinSoaJuIuHcgLHMbIFqZPftaRzrksQD4b9Iu4YGFumbOQbSknRbP23GtiqmFy6llMfXgcjyyP39+/XGZu+s/Xa8HUOvMtfZKijVupy/O20BfThVi7tYx6L7y+fXHZe6u/3QD/Y9ya0Xe5Y6Ixfla4CslbUW6jKyn22mlVsY0kJcTkuZ2VEU6sd8bBvQyt4FhQP9RDnhM0vj2gfxF+jvyCa5eaKeVWhnTQF5OkJLAPwIfL+ma/pd3iwz0ZW4DwIA+SS1pBLAyIv5SUvf+iPhtT7bTSq2MaSAvp/zeF5EuR/5NSd3lEXFYyWR1xzSgl7kNDAM6QZiZWfcN9ENMZmbWTU4QZmZWygnCrAuSjst3yv2vJqcb3XgXYbP+xAnCrGvHAB+NiH9ocrrRQNMJQtKgZqcxq4MThFknJF0AbA1cI+kkSRdLukvSPe3POMh7Crfn54bMlvS+PPkZwB6S5kg6QdIRks4ttH11+336JT0n6WxJfwB2l/ReSbdJulvSdc08l8OsVZwgzDoREV8A/gx8iHSv/5sjYkIe/o6kDYDHSXsYOwOfJj3gBtLtxW+PiPER8d0u3moD0r2UdiTdm+kHwMER8V7Sw5O+1eJZM+vSQP8ntVkr7QMcIOmreXgw6WEsfwbOzX9YW0V6ZkWzVpEeaAWwHfBu4AZJkG4t/+gaxG3WLU4QZtUJ+GRELHhDoXQq6TkRO5L2yl/qYPqVvHGvfXCh/6WIWFV4n/kRsXsrgjbrLh9iMqvuOuDLyj/rJe2UyzchPd7zNeBw0i9+SE8I26gw/WJgvKS1JI0kPeS+zAJgmKTd8/usI2n7ls6JWQVOEGbVfZP0iNi5kubnYUiPoJ2UTzC/E3g+l88FVkn6g6QTSI+7/RNwH+k8xeyyN4mIV0gPfTkztzkHeF/ZuGZ18q02zMyslPcgzMyslBOEmZmVcoIwM7NSThBmZlbKCcLMzEo5QZiZWSknCDMzK+UEYWZmpf4/InOqe/QvKnUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13279e810>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.plot_feature_importance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access raw results\n",
    "You can also get access to all the underlying data like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {'id': 0,\n",
       "  'pipeline_name': 'XGBoostPipeline',\n",
       "  'parameters': {'eta': 0.5928446182250184,\n",
       "   'min_child_weight': 8.598391737229157,\n",
       "   'max_depth': 4,\n",
       "   'impute_strategy': 'most_frequent',\n",
       "   'percent_features': 0.6273280598181127},\n",
       "  'score': 0.9651954750600785,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9586776859504134, 0.9752066115702479, 0.9617021276595743],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9586776859504134),\n",
       "                ('Precision', 0.943089430894309),\n",
       "                ('Recall', 0.9586776859504134),\n",
       "                ('AUC', 0.9865664575689431),\n",
       "                ('Log Loss', 0.14983175628279385),\n",
       "                ('MCC', 0.8871869342405617),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9752066115702479),\n",
       "                ('Precision', 0.959349593495935),\n",
       "                ('Recall', 0.9752066115702479),\n",
       "                ('AUC', 0.9955616049236596),\n",
       "                ('Log Loss', 0.10579590414111552),\n",
       "                ('MCC', 0.9327267201397125),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9617021276595743),\n",
       "                ('Precision', 0.9741379310344828),\n",
       "                ('Recall', 0.9617021276595743),\n",
       "                ('AUC', 0.9829531812725091),\n",
       "                ('Log Loss', 0.13361063377843016),\n",
       "                ('MCC', 0.8993040708411105),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 0.23534393310546875},\n",
       " 1: {'id': 1,\n",
       "  'pipeline_name': 'XGBoostPipeline',\n",
       "  'parameters': {'eta': 0.38438170729269994,\n",
       "   'min_child_weight': 3.677811458900251,\n",
       "   'max_depth': 13,\n",
       "   'impute_strategy': 'median',\n",
       "   'percent_features': 0.793807787701838},\n",
       "  'score': 0.9706738245383719,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9666666666666667, 0.979253112033195, 0.9661016949152542],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9666666666666667),\n",
       "                ('Precision', 0.9586776859504132),\n",
       "                ('Recall', 0.9666666666666667),\n",
       "                ('AUC', 0.9918333530595337),\n",
       "                ('Log Loss', 0.11837350234119712),\n",
       "                ('MCC', 0.9097672817424011),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.979253112033195),\n",
       "                ('Precision', 0.9672131147540983),\n",
       "                ('Recall', 0.979253112033195),\n",
       "                ('AUC', 0.9963309267368918),\n",
       "                ('Log Loss', 0.08243243813477946),\n",
       "                ('MCC', 0.943843520216036),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9661016949152542),\n",
       "                ('Precision', 0.9743589743589743),\n",
       "                ('Recall', 0.9661016949152542),\n",
       "                ('AUC', 0.9858343337334934),\n",
       "                ('Log Loss', 0.1252105505447145),\n",
       "                ('MCC', 0.9100059668642326),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 0.31885480880737305},\n",
       " 2: {'id': 2,\n",
       "  'pipeline_name': 'RFClassificationPipeline',\n",
       "  'parameters': {'n_estimators': 569,\n",
       "   'max_depth': 22,\n",
       "   'impute_strategy': 'most_frequent',\n",
       "   'percent_features': 0.8593661614465293},\n",
       "  'score': 0.9668456397284798,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9508196721311476, 0.979253112033195, 0.970464135021097],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9508196721311476),\n",
       "                ('Precision', 0.928),\n",
       "                ('Recall', 0.9508196721311476),\n",
       "                ('AUC', 0.9889336016096579),\n",
       "                ('Log Loss', 0.1388421748025717),\n",
       "                ('MCC', 0.8647724688764672),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.979253112033195),\n",
       "                ('Precision', 0.9672131147540983),\n",
       "                ('Recall', 0.979253112033195),\n",
       "                ('AUC', 0.9898804592259438),\n",
       "                ('Log Loss', 0.11232987225229708),\n",
       "                ('MCC', 0.943843520216036),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.970464135021097),\n",
       "                ('Precision', 0.9745762711864406),\n",
       "                ('Recall', 0.970464135021097),\n",
       "                ('AUC', 0.9906362545018007),\n",
       "                ('Log Loss', 0.11575295379524118),\n",
       "                ('MCC', 0.9208800271662652),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 6.081725835800171},\n",
       " 3: {'id': 3,\n",
       "  'pipeline_name': 'XGBoostPipeline',\n",
       "  'parameters': {'eta': 0.5288949197529046,\n",
       "   'min_child_weight': 6.112401049845392,\n",
       "   'max_depth': 6,\n",
       "   'impute_strategy': 'most_frequent',\n",
       "   'percent_features': 0.34402219881309576},\n",
       "  'score': 0.9607393479447351,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9504132231404958, 0.9794238683127572, 0.9523809523809523],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9504132231404958),\n",
       "                ('Precision', 0.9349593495934959),\n",
       "                ('Recall', 0.9504132231404958),\n",
       "                ('AUC', 0.9865664575689431),\n",
       "                ('Log Loss', 0.14135858728060205),\n",
       "                ('MCC', 0.8644170412909863),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9794238683127572),\n",
       "                ('Precision', 0.9596774193548387),\n",
       "                ('Recall', 0.9794238683127572),\n",
       "                ('AUC', 0.9960350337318026),\n",
       "                ('Log Loss', 0.08963871603513038),\n",
       "                ('MCC', 0.9445075449666159),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9523809523809523),\n",
       "                ('Precision', 0.9821428571428571),\n",
       "                ('Recall', 0.9523809523809523),\n",
       "                ('AUC', 0.985954381752701),\n",
       "                ('Log Loss', 0.13301814707838708),\n",
       "                ('MCC', 0.8803966271554114),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 0.26305198669433594},\n",
       " 4: {'id': 4,\n",
       "  'pipeline_name': 'LogisticRegressionPipeline',\n",
       "  'parameters': {'penalty': 'l2',\n",
       "   'C': 8.444214828324364,\n",
       "   'impute_strategy': 'most_frequent'},\n",
       "  'score': 0.9734109818152151,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.970464135021097, 0.9754098360655737, 0.9743589743589743],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.970464135021097),\n",
       "                ('Precision', 0.9745762711864406),\n",
       "                ('Recall', 0.970464135021097),\n",
       "                ('AUC', 0.9885193514025328),\n",
       "                ('Log Loss', 0.19432945908194826),\n",
       "                ('MCC', 0.9215733295732883),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9754098360655737),\n",
       "                ('Precision', 0.952),\n",
       "                ('Recall', 0.9754098360655737),\n",
       "                ('AUC', 0.9849686353414605),\n",
       "                ('Log Loss', 0.1533799764176718),\n",
       "                ('MCC', 0.933568045604951),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9743589743589743),\n",
       "                ('Precision', 0.991304347826087),\n",
       "                ('Recall', 0.9743589743589743),\n",
       "                ('AUC', 0.990516206482593),\n",
       "                ('Log Loss', 0.1164316714613046),\n",
       "                ('MCC', 0.9336637889421326),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 3.545822858810425},\n",
       " 5: {'id': 5,\n",
       "  'pipeline_name': 'XGBoostPipeline',\n",
       "  'parameters': {'eta': 0.6481718720511973,\n",
       "   'min_child_weight': 4.314173858564932,\n",
       "   'max_depth': 6,\n",
       "   'impute_strategy': 'most_frequent',\n",
       "   'percent_features': 0.871312026764351},\n",
       "  'score': 0.969254157920668,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9623430962343097, 0.9752066115702479, 0.9702127659574468],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9623430962343097),\n",
       "                ('Precision', 0.9583333333333334),\n",
       "                ('Recall', 0.9623430962343097),\n",
       "                ('AUC', 0.9901763522310333),\n",
       "                ('Log Loss', 0.12383983944248604),\n",
       "                ('MCC', 0.8985734479173947),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9752066115702479),\n",
       "                ('Precision', 0.959349593495935),\n",
       "                ('Recall', 0.9752066115702479),\n",
       "                ('AUC', 0.9962125695348562),\n",
       "                ('Log Loss', 0.08514171470765416),\n",
       "                ('MCC', 0.9327267201397125),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9702127659574468),\n",
       "                ('Precision', 0.9827586206896551),\n",
       "                ('Recall', 0.9702127659574468),\n",
       "                ('AUC', 0.9860744297719087),\n",
       "                ('Log Loss', 0.12377072123640645),\n",
       "                ('MCC', 0.9218075091290715),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 0.3598449230194092},\n",
       " 6: {'id': 6,\n",
       "  'pipeline_name': 'LogisticRegressionPipeline',\n",
       "  'parameters': {'penalty': 'l2',\n",
       "   'C': 6.239401330891865,\n",
       "   'impute_strategy': 'median'},\n",
       "  'score': 0.9748529087969783,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9747899159663865, 0.9754098360655737, 0.9743589743589743],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9747899159663865),\n",
       "                ('Precision', 0.9747899159663865),\n",
       "                ('Recall', 0.9747899159663865),\n",
       "                ('AUC', 0.9889927802106758),\n",
       "                ('Log Loss', 0.174912415672324),\n",
       "                ('MCC', 0.932536394839626),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9754098360655737),\n",
       "                ('Precision', 0.952),\n",
       "                ('Recall', 0.9754098360655737),\n",
       "                ('AUC', 0.9870990649781038),\n",
       "                ('Log Loss', 0.13982009938626028),\n",
       "                ('MCC', 0.933568045604951),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9743589743589743),\n",
       "                ('Precision', 0.991304347826087),\n",
       "                ('Recall', 0.9743589743589743),\n",
       "                ('AUC', 0.990516206482593),\n",
       "                ('Log Loss', 0.11096455834029183),\n",
       "                ('MCC', 0.9336637889421326),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 3.725893020629883},\n",
       " 7: {'id': 7,\n",
       "  'pipeline_name': 'XGBoostPipeline',\n",
       "  'parameters': {'eta': 0.9786183422327642,\n",
       "   'min_child_weight': 8.192427077950514,\n",
       "   'max_depth': 20,\n",
       "   'impute_strategy': 'median',\n",
       "   'percent_features': 0.6820907348177707},\n",
       "  'score': 0.9651954750600785,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9586776859504134, 0.9752066115702479, 0.9617021276595743],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9586776859504134),\n",
       "                ('Precision', 0.943089430894309),\n",
       "                ('Recall', 0.9586776859504134),\n",
       "                ('AUC', 0.986566457568943),\n",
       "                ('Log Loss', 0.1476227625175134),\n",
       "                ('MCC', 0.8871869342405617),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9752066115702479),\n",
       "                ('Precision', 0.959349593495935),\n",
       "                ('Recall', 0.9752066115702479),\n",
       "                ('AUC', 0.9962125695348562),\n",
       "                ('Log Loss', 0.09923503662116434),\n",
       "                ('MCC', 0.9327267201397125),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9617021276595743),\n",
       "                ('Precision', 0.9741379310344828),\n",
       "                ('Recall', 0.9617021276595743),\n",
       "                ('AUC', 0.9834333733493397),\n",
       "                ('Log Loss', 0.13148702966620918),\n",
       "                ('MCC', 0.8993040708411105),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 0.26704883575439453},\n",
       " 8: {'id': 8,\n",
       "  'pipeline_name': 'LogisticRegressionPipeline',\n",
       "  'parameters': {'penalty': 'l2',\n",
       "   'C': 0.5765626434012575,\n",
       "   'impute_strategy': 'mean'},\n",
       "  'score': 0.9805269796885542,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9874476987447698, 0.9754098360655737, 0.9787234042553192],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9874476987447698),\n",
       "                ('Precision', 0.9833333333333333),\n",
       "                ('Recall', 0.9874476987447698),\n",
       "                ('AUC', 0.994910640312463),\n",
       "                ('Log Loss', 0.08726565374201165),\n",
       "                ('MCC', 0.9662335358054943),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9754098360655737),\n",
       "                ('Precision', 0.952),\n",
       "                ('Recall', 0.9754098360655737),\n",
       "                ('AUC', 0.9979879275653923),\n",
       "                ('Log Loss', 0.07645591278007538),\n",
       "                ('MCC', 0.933568045604951),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9787234042553192),\n",
       "                ('Precision', 0.9913793103448276),\n",
       "                ('Recall', 0.9787234042553192),\n",
       "                ('AUC', 0.9903961584633854),\n",
       "                ('Log Loss', 0.09774553003325112),\n",
       "                ('MCC', 0.9443109474170326),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 3.8701398372650146},\n",
       " 9: {'id': 9,\n",
       "  'pipeline_name': 'LogisticRegressionPipeline',\n",
       "  'parameters': {'penalty': 'l2',\n",
       "   'C': 8.123565600467177,\n",
       "   'impute_strategy': 'median'},\n",
       "  'score': 0.9748529087969783,\n",
       "  'high_variance_cv': False,\n",
       "  'scores': [0.9747899159663865, 0.9754098360655737, 0.9743589743589743],\n",
       "  'all_objective_scores': [OrderedDict([('F1', 0.9747899159663865),\n",
       "                ('Precision', 0.9747899159663865),\n",
       "                ('Recall', 0.9747899159663865),\n",
       "                ('AUC', 0.9886377086045686),\n",
       "                ('Log Loss', 0.1917051028291318),\n",
       "                ('MCC', 0.932536394839626),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9754098360655737),\n",
       "                ('Precision', 0.952),\n",
       "                ('Recall', 0.9754098360655737),\n",
       "                ('AUC', 0.9850869925434962),\n",
       "                ('Log Loss', 0.15159254810086167),\n",
       "                ('MCC', 0.933568045604951),\n",
       "                ('# Training', 379),\n",
       "                ('# Testing', 190)]),\n",
       "   OrderedDict([('F1', 0.9743589743589743),\n",
       "                ('Precision', 0.991304347826087),\n",
       "                ('Recall', 0.9743589743589743),\n",
       "                ('AUC', 0.990516206482593),\n",
       "                ('Log Loss', 0.1156693063457744),\n",
       "                ('MCC', 0.9336637889421326),\n",
       "                ('# Training', 380),\n",
       "                ('# Testing', 189)])],\n",
       "  'training_time': 3.9845199584960938}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
