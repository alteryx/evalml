{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![EvalML Logo](images/evalml_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# What is EvalML?\n",
    "EvalML is an AutoML library that builds, optimizes, and evaluates machine learning pipelines using domain-specific objective functions. \n",
    "\n",
    "Combined with [Featuretools](https://featuretools.featurelabs.com) and [Compose](https://compose.featurelabs.com), EvalML can be used to create end-to-end machine learning solutions for classification and regression problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install\n",
    "\n",
    "EvalML is available for Python 3.5+. It can be installed by running the following command:\n",
    "```bash\n",
    "    pip install evaml --extra-index-url https://install.featurelabs.com/<license>/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note for Windows users**: The [XGBoost](https://pypi.org/project/xgboost/) library may not be pip-installable in some Windows environments. If you are encountering installation issues, please try installing XGBoost from [Github](https://xgboost.readthedocs.io/en/latest/build.html) before installing EvalML. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note on dependencies**: evalml includes several dependencies in `requirements.txt` by default: `xgboost` and `catboost` support pipelines built around those modeling libraries, and `plotly` and `ipywidgets` support plotting functionality in automl searches. These dependencies are not required in order to install and use evalml.\n",
    "\n",
    "If you wish to install evalml with only the core required dependencies, run `pip install --no-dependencies evalml` and then install all other dependencies by hand. To avoid unknown errors, be sure to include all other dependencies when you do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalml\n",
    "from evalml import AutoClassificationSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "First, we load in the features and outcomes we want to use to train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = evalml.demos.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure search\n",
    "\n",
    "EvalML has many options to configure the pipeline search. At the minimum, we need to define an objective function. For simplicity, we will use the F1 score in this example. However, the real power of EvalML is in using domain-specific [objective functions](objectives/overview.ipynb) or [building your own](objectives/custom_objectives.ipynb).\n",
    "\n",
    "Below EvalML utilizes Bayesian optimization (EvalML's default optimizer) to search and find the best pipeline defined by the given objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoClassificationSearch(objective=\"f1\",\n",
    "                                  max_pipelines=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to validate the results of the pipeline creation and optimization process, we will save some of our data as a holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_holdout, y_train, y_holdout = evalml.preprocessing.split_data(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we call `.search()`, the search for the best pipeline will begin. There is no need to wrangle with missing data or categorical variables as EvalML includes various preprocessing steps (like imputation, one-hot encoding, feature selection) to ensure you're getting the best results. As long as your data is in a single table, EvalML can handle it. If not, you can reduce your data to a single table by utilizing [Featuretools](https://featuretools.featurelabs.com) and its Entity Sets.\n",
    "\n",
    "You can find more information on pipeline components and how to integrate your own custom pipelines into EvalML [here](pipelines/overview.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.search(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See Pipeline Rankings\n",
    "\n",
    "After the search is finished we can view all of the pipelines searched, ranked by score. Internally, EvalML performs cross validation to score the pipelines. If it notices a high variance across cross validation folds, it will warn you. EvalML also provides additional [guardrails](guardrails/overview.ipynb) to analyze your data to assist you in producing the best performing pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe pipeline\n",
    "\n",
    "If we are interested in see more details about the pipeline, we can describe it using the `id` from the rankings table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl.describe_pipeline(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Best pipeline\n",
    "We can now select best pipeline and score it on our holdout data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = automl.best_pipeline\n",
    "pipeline.score(X_holdout, y_holdout, [\"f1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the structure of our pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whats next?\n",
    "\n",
    "Head into the more in-depth automated walkthrough [here](automl/pipeline_search.ipynb) or any advanced topics below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx-toctree": {
     "maxdepth": 1
    }
   },
   "source": [
    "# Getting Started\n",
    "[What is EvalML](self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx-toctree": {
     "maxdepth": 1
    }
   },
   "source": [
    "# Objective functions\n",
    "\n",
    "[Overview](objectives/overview)\n",
    "\n",
    "[Fraud Prediction](demos/fraud)\n",
    "\n",
    "[Lead Scoring](demos/lead_scoring)\n",
    "\n",
    "[Defining Custom Objectives](objectives/custom_objectives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx-toctree": {
     "maxdepth": 1
    }
   },
   "source": [
    "# Automated Machine Learning\n",
    "\n",
    "[Setting up pipeline search](automl/pipeline_search)\n",
    "\n",
    "[Exploring search results](automl/search_results)\n",
    "\n",
    "[Regression Example](automl/regression_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx-toctree": {
     "maxdepth": 1
    }
   },
   "source": [
    "# Components and Custom Pipelines\n",
    "\n",
    "[Overview](pipelines/overview)\n",
    "\n",
    "[Components](pipelines/components)\n",
    "\n",
    "[Custom Pipelines](pipelines/custom_pipelines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx-toctree": {
     "maxdepth": 1
    }
   },
   "source": [
    "# Guardrails\n",
    "\n",
    "[Overview](guardrails/overview)\n",
    "\n",
    "[Overfitting Guardrails](guardrails/overfitting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx-toctree": {
     "maxdepth": 1
    }
   },
   "source": [
    "# Resources\n",
    "[Changelog](changelog)\n",
    "\n",
    "[API Reference](api_reference)\n",
    "\n",
    "[FAQ](faq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}