{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![EvalML Logo](images/evalml_logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# What is EvalML?\n",
    "EvalML is an AutoML library that builds, optimizes, and evalutes machine learning pipelines using domain-specific objective functions.\n",
    "\n",
    "\n",
    "Combined with [Featuretools](https://featuretools.featurelabs.com) and [Compose](https://compose.featurelabs.com), EvalML can be used to create end-to-end machine learning solutions for classification and regression problems. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "First, we load in the features and outcomes we want to use to train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = evalml.demos.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure search\n",
    "\n",
    "EvalML has many options to configure the pipeline search. At the minimum, we need to define an objective function. For simplicity, we will use the F1 score in this example. However, the real power of EvalML is in using domain-specific [objective functions](objectives/overview.html) or [building your own](objectives/custom_objectives.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = evalml.AutoClassifier(objective=\"f1\",\n",
    "                            max_pipelines=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to validate the results of the pipeline creation and optimization process, we will save some of our data as a holdout set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_holdout, y_train, y_holdout = evalml.preprocessing.split_data(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we call `.fit()`, the search for the best pipeline will begin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m*****************************\u001b[0m\n",
      "\u001b[1m* Beginning pipeline search *\u001b[0m\n",
      "\u001b[1m*****************************\u001b[0m\n",
      "\n",
      "Optimizing for F1. Greater score is better.\n",
      "\n",
      "Searching up to 5 pipelines. \n",
      "Possible model types: xgboost, linear_model, random_forest\n",
      "\n",
      "✔ XGBoost Classifier w/ One Hot Encod...     0%|          | Elapsed:00:02\n",
      "✔ XGBoost Classifier w/ One Hot Encod...    20%|██        | Elapsed:00:04\n",
      "✔ Random Forest Classifier w/ One Hot...    40%|████      | Elapsed:00:14\n",
      "✔ XGBoost Classifier w/ One Hot Encod...    60%|██████    | Elapsed:00:16\n",
      "✔ Logistic Regression Classifier w/ O...    80%|████████  | Elapsed:00:22\n",
      "✔ Logistic Regression Classifier w/ O...   100%|██████████| Elapsed:00:22\n",
      "\n",
      "✔ Optimization finished\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See Pipeline Rankings\n",
    "\n",
    "After the search is finished we can view all of the pipelines searched, ranked by score. Internally, EvalML performs [cross validation](automl/guardrails.html) to score the pipelines. If it notices a high variance across cross validation folds, it will warn you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>score</th>\n",
       "      <th>high_variance_cv</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>RFClassificationPipeline</td>\n",
       "      <td>0.973822</td>\n",
       "      <td>False</td>\n",
       "      <td>{'n_estimators': 569, 'max_depth': 22, 'impute...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegressionPipeline</td>\n",
       "      <td>0.971963</td>\n",
       "      <td>False</td>\n",
       "      <td>{'penalty': 'l2', 'C': 8.444214828324364, 'imp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>0.970312</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.38438170729269994, 'min_child_weight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>0.959800</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.5928446182250184, 'min_child_weight'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>XGBoostPipeline</td>\n",
       "      <td>0.957570</td>\n",
       "      <td>False</td>\n",
       "      <td>{'eta': 0.5288949197529046, 'min_child_weight'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id               pipeline_name     score  high_variance_cv  \\\n",
       "0   2    RFClassificationPipeline  0.973822             False   \n",
       "1   4  LogisticRegressionPipeline  0.971963             False   \n",
       "2   1             XGBoostPipeline  0.970312             False   \n",
       "3   0             XGBoostPipeline  0.959800             False   \n",
       "4   3             XGBoostPipeline  0.957570             False   \n",
       "\n",
       "                                          parameters  \n",
       "0  {'n_estimators': 569, 'max_depth': 22, 'impute...  \n",
       "1  {'penalty': 'l2', 'C': 8.444214828324364, 'imp...  \n",
       "2  {'eta': 0.38438170729269994, 'min_child_weight...  \n",
       "3  {'eta': 0.5928446182250184, 'min_child_weight'...  \n",
       "4  {'eta': 0.5288949197529046, 'min_child_weight'...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe pipeline\n",
    "\n",
    "If we are interested in see more details about the pipeline we can describe it using the `id` from the rankings table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m************************\u001b[0m\n",
      "\u001b[1m* Pipeline Description *\u001b[0m\n",
      "\u001b[1m************************\u001b[0m\n",
      "\n",
      "Pipeline Name: XGBoost Classifier w/ One Hot Encoder + Simple Imputer + RF Classifier Select From Model\n",
      "Model type: ModelTypes.XGBOOST\n",
      "Objective: F1 (greater is better)\n",
      "Total training time (including CV): 2.4 seconds\n",
      "\n",
      "Parameters\n",
      "==========\n",
      "• eta: 0.5288949197529046\n",
      "• min_child_weight: 6.112401049845392\n",
      "• max_depth: 6\n",
      "• impute_strategy: most_frequent\n",
      "• percent_features: 0.34402219881309576\n",
      "\n",
      "Cross Validation\n",
      "=================\n",
      "               F1  Precision  Recall   AUC  Log Loss   MCC # Training # Testing\n",
      "0           0.974      0.959   0.974 0.995     0.100 0.930    303.000   152.000\n",
      "1           0.946      0.967   0.946 0.985     0.147 0.863    303.000   152.000\n",
      "2           0.952      0.957   0.952 0.987     0.155 0.873    304.000   151.000\n",
      "mean        0.958      0.961   0.958 0.989     0.134 0.889          -         -\n",
      "std         0.015      0.005   0.015 0.006     0.030 0.036          -         -\n",
      "coef of var 0.015      0.005   0.015 0.006     0.222 0.041          -         -\n"
     ]
    }
   ],
   "source": [
    "clf.describe_pipeline(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Best pipeline\n",
    "We can now select best pipeline and score it on our holdout data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.951048951048951, {})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = clf.best_pipeline\n",
    "pipeline.score(X_holdout, y_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See Feature Importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are able to create a bar chart of features ranked by importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720a7cc838db4e7baf4d5f6907a7e5bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'orientation': 'h',\n",
       "              'type': 'bar',\n",
       "              'uid': '6b09dcd0-4…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline.plot_feature_importances()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx-toctree": {
     "maxdepth": 1
    }
   },
   "source": [
    "# Getting Started\n",
    "[What is EvalML](self)\n",
    "\n",
    "[Install](install)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx-toctree": {
     "maxdepth": 1
    }
   },
   "source": [
    "# Objective functions\n",
    "\n",
    "[Overview](objectives/overview)\n",
    "\n",
    "[Fraud Prediction](demos/fraud)\n",
    "\n",
    "[Lead Scoring](demos/lead_scoring)\n",
    "\n",
    "[Defining Custom Objectives](objectives/custom_objectives)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx-toctree": {
     "maxdepth": 1
    }
   },
   "source": [
    "# Automated Machine Learning\n",
    "\n",
    "[Setting up pipeline search](automl/pipeline_search)\n",
    "\n",
    "[Exploring search results](automl/search_results)\n",
    "\n",
    "[Avoiding Overfitting](automl/guardrails)\n",
    "\n",
    "[Regression Example](automl/regression_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbsphinx-toctree": {
     "maxdepth": 1
    }
   },
   "source": [
    "# Resources\n",
    "[Changelog](changelog)\n",
    "\n",
    "[Roadmap](roadmap)\n",
    "\n",
    "[API Reference](api_reference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
