{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EvalML provides data checks to help guide you in achieving the highest performing model. These utility functions help deal with overfitting, abnormal data, and missing data. These data checks can be found under `evalml/data_checks`. Below we will cover abnormal and missing data data checks. You can find an in-depth look into overfitting data checks [here](data_checks.ipynb). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Data\n",
    "\n",
    "Missing data or rows with `NaN` values provide many challenges for machine learning pipelines. In the worst case, many algorithms simply will not run with missing data! EvalML pipelines contain imputation [components](../pipelines/components.ipynb) to ensure that doesn't happen. Imputation works by approximating missing values with existing values. However, if a column contains a high number of missing values a large percentage of the column would be approximated by a small percentage. This could potentially create a column without useful information for machine learning pipelines. By running the `detect_highly_null()` guardrail, EvalML will alert you to this potential problem by returning the columns that pass the missing values threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from evalml.guardrails.utils import detect_highly_null\n",
    "\n",
    "X = pd.DataFrame(\n",
    "    [\n",
    "        [1, 2, 3], \n",
    "        [0, 4, np.nan],\n",
    "        [1, 4, np.nan],\n",
    "        [9, 4, np.nan],\n",
    "        [8, 6, np.nan]\n",
    "    ]\n",
    ")\n",
    "\n",
    "detect_highly_null(X, percent_threshold=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abnormal Data\n",
    "\n",
    "EvalML provides two utility functions to check for abnormal data: `detect_outliers()` and `detect_id_columns()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID Columns\n",
    "\n",
    "ID columns in your dataset provide little to no benefit to a machine learning pipeline as the pipeline cannot extrapolate useful information from unique identifiers. Thus, `detect_id_columns()` reminds you if these columns exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalml.guardrails.utils import detect_id_columns\n",
    "\n",
    "X = pd.DataFrame([[0, 53, 6325, 5],[1, 90, 6325, 10],[2, 90, 18, 20]], columns=['user_number', 'cost', 'revenue', 'id'])\n",
    "\n",
    "\n",
    "display(X)\n",
    "print(detect_id_columns(X, threshold=0.95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "\n",
    "Outliers are observations that differ significantly from other observations in the same sample. Many machine learning pipelines suffer in performance if outliers are not dropped from the training set as they are not representative of the data. `detect_outliers()` uses Isolation Forests to notify you if a sample can be considered an outlier.\n",
    "\n",
    "Below we generate a random dataset with some outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.randn(100, 100)\n",
    "X = pd.DataFrame(data=data)\n",
    "\n",
    "# outliers\n",
    "X.iloc[3, :] = pd.Series(np.random.randn(100) * 10)\n",
    "X.iloc[25, :] = pd.Series(np.random.randn(100) * 20)\n",
    "X.iloc[55, :] = pd.Series(np.random.randn(100) * 100)\n",
    "X.iloc[72, :] = pd.Series(np.random.randn(100) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then utilize `detect_outliers` to rediscover these outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalml.guardrails.utils import detect_outliers\n",
    "\n",
    "detect_outliers(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
