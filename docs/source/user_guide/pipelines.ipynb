{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "\n",
    "EvalML pipelines represent a sequence of operations to be applied to data, where each operation is either a data transformation or an ML modeling algorithm.\n",
    "\n",
    "A pipeline class holds a combination of one or more components, which will be applied to new input data in sequence.\n",
    "\n",
    "Each component and pipeline class supports a set of parameters which configure its behavior. The AutoML search process seeks to find the combination of pipeline structure and pipeline parameters which perform the best on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Definition\n",
    "Pipeline definitions must inherit from the proper pipeline base class, `RegressionPipeline`, `BinaryClassificationPipeline` or `MulticlassClassificationPipeline`. They must also include a `component_graph` list as a class variable containing the sequence of components to be fit and evaluated. Each component in the graph can be provided as either a string name or as a reference to the component class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalml.pipelines import MulticlassClassificationPipeline\n",
    "\n",
    "class CustomMulticlassClassificationPipeline(MulticlassClassificationPipeline):\n",
    "    component_graph = ['Simple Imputer', 'Random Forest Classifier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're using your own [custom components](components.ipynb) you can refer to them like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalml.pipelines.components import Transformer\n",
    "\n",
    "class NewTransformer(Transformer):\n",
    "    name = 'New Transformer'\n",
    "    hyperparameter_ranges = {\n",
    "        \"parameter_1\":['a', 'b', 'c']\n",
    "    }\n",
    "    \n",
    "    def __init__(self, parameter_1, random_state):\n",
    "        transformer = ThirdPartyTransformer(parameter_1)\n",
    "        parameters = {\"parameter_1\": parameter_1}\n",
    "        super().__init__(parameters=parameters,\n",
    "                         component_obj=transformer,\n",
    "                         random_state=random_state)\n",
    "    \n",
    "class CustomComponentMulticlassClassificationPipeline(MulticlassClassificationPipeline):\n",
    "    component_graph = [NewTransformer, 'Random Forest Classifier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Usage\n",
    "\n",
    "All pipelines define the following methods:\n",
    "\n",
    "* `fit` fits each component on the provided training data, in order.\n",
    "\n",
    "* `predict` computes the predictions of the component graph on the provided data.\n",
    "\n",
    "* `score` computes the value of [an objective](objectives.ipynb) on the provided data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalml.demos import load_wine\n",
    "X, y = load_wine()\n",
    "\n",
    "pipeline = CustomMulticlassClassificationPipeline({})\n",
    "pipeline.fit(X, y)\n",
    "print(pipeline.predict(X))\n",
    "print(pipeline.score(X, y, objectives=['log loss multiclass']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Name\n",
    "By default, a pipeline class's name property is the result of adding spaces between each Pascal case capitalization in the class name. E.g. `LogisticRegressionPipeline.name` will return 'Logistic Regression Pipeline'. Therefore, we suggest custom pipelines use Pascal case for their class names.\n",
    "\n",
    "If you'd like to override the pipeline classes name attribute so it isn't derived from the class name, you can set the custom_name attribute, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalml.pipelines import MulticlassClassificationPipeline\n",
    "\n",
    "class CustomPipeline(MulticlassClassificationPipeline):\n",
    "    component_graph = ['Simple Imputer', 'One Hot Encoder', 'Logistic Regression Classifier']\n",
    "    custom_name = 'A custom pipeline name'\n",
    "    \n",
    "print(CustomPipeline.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Override Component Hyperparameter Ranges\n",
    "To specify custom hyperparameter ranges, set the `custom_hyperparameters` property to be a dictionary where each key-value pair consists of a parameter name and range. AutoML will use this dictionary to override the hyperparameter ranges collected from each component in the component graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPipeline(MulticlassClassificationPipeline):\n",
    "    component_graph = ['Simple Imputer', 'One Hot Encoder', 'Standard Scaler', 'Logistic Regression Classifier']\n",
    "\n",
    "print(\"Without custom hyperparameters:\")\n",
    "print(CustomPipeline.hyperparameters)  \n",
    "    \n",
    "class CustomPipeline(MulticlassClassificationPipeline):\n",
    "        component_graph = ['Simple Imputer', 'One Hot Encoder', 'Standard Scaler', 'Logistic Regression Classifier']\n",
    "        custom_hyperparameters = {\n",
    "        'Simple Imputer' : {\n",
    "            'impute_strategy': ['most_frequent']\n",
    "        }\n",
    "    }\n",
    "\n",
    "print()\n",
    "print(\"With custom hyperparameters:\")\n",
    "print(CustomPipeline.hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize our new custom pipeline class, we must pass in a `parameters` argument. If we want to use the defaults for each component, we can simply pass in an empty dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CustomPipeline(parameters={})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Parameters\n",
    "You can also pass in custom parameters. The parameters dictionary needs to be in the format of a two-layered dictionary where the first key-value pair is the component name and component parameters dictionary. The component parameters dictionary consists of a key value pair of parameter name and parameter values. An example will be shown below and component parameters can be found [here](../api_reference.rst#components)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        'Simple Imputer': {\n",
    "            'impute_strategy': 'mean'\n",
    "        },\n",
    "        'Logistic Regression Classifier': {\n",
    "            'penalty': 'l2',\n",
    "            'C': 1.0,\n",
    "        }\n",
    "    }\n",
    "\n",
    "cp = CustomPipeline(parameters=parameters, random_state=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Description\n",
    "\n",
    "You can call `.graph()` to see each component and its parameters. Each component takes in data and feeds it to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see a textual representation of the pipeline by calling `.describe()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
