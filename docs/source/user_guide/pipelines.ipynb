{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "\n",
    "EvalML pipelines represent a sequence of operations to be applied to data, where each operation is either a data transformation or an ML modeling algorithm.\n",
    "\n",
    "A pipeline class holds a combination of one or more components, which will be applied to new input data in sequence.\n",
    "\n",
    "Each component and pipeline class supports a set of parameters which configure its behavior. The AutoML search process seeks to find the combination of pipeline structure and pipeline parameters which perform the best on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Definition\n",
    "Pipeline definitions must inherit from the proper pipeline base class, `RegressionPipeline`, `BinaryClassificationPipeline` or `MulticlassClassificationPipeline`. They must also include a `component_graph` list as a class variable containing the sequence of components to be fit and evaluated. The `component_graph` list is used to determine the ordered list of components that should be instantiated when a pipeline instance is created. Each component in `component_graph` can be provided as a reference to the component class for custom components, and as either a string name or as a reference to the component class for components defined in EvalML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-11-24 23:07:12,116 featuretools - WARNING    Featuretools failed to load plugin nlp_primitives from library nlp_primitives. For a full stack trace, set logging to debug.\n"
     ]
    }
   ],
   "source": [
    "from evalml.pipelines import MulticlassClassificationPipeline\n",
    "\n",
    "class CustomMulticlassClassificationPipeline(MulticlassClassificationPipeline):\n",
    "    component_graph = ['Imputer', 'Random Forest Classifier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're using your own [custom components](components.ipynb) you can refer to them like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalml.pipelines.components import Transformer\n",
    "\n",
    "class NewTransformer(Transformer):\n",
    "    name = 'New Transformer'\n",
    "    hyperparameter_ranges = {\n",
    "        \"parameter_1\":['a', 'b', 'c']\n",
    "    }\n",
    "    \n",
    "    def __init__(self, parameter_1, random_state):\n",
    "        transformer = ThirdPartyTransformer(parameter_1)\n",
    "        parameters = {\"parameter_1\": parameter_1}\n",
    "        super().__init__(parameters=parameters,\n",
    "                         component_obj=transformer,\n",
    "                         random_state=random_state)\n",
    "    \n",
    "class CustomComponentMulticlassClassificationPipeline(MulticlassClassificationPipeline):\n",
    "    component_graph = [NewTransformer, 'Random Forest Classifier']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Usage\n",
    "\n",
    "All pipelines define the following methods:\n",
    "\n",
    "* `fit` fits each component on the provided training data, in order.\n",
    "\n",
    "* `predict` computes the predictions of the component graph on the provided data.\n",
    "\n",
    "* `score` computes the value of [an objective](objectives.ipynb) on the provided data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<woodwork.data_table.DataTable object at 0x10d017cd0>\n",
      "0      class_0\n",
      "1      class_0\n",
      "2      class_0\n",
      "3      class_0\n",
      "4      class_0\n",
      "        ...   \n",
      "173    class_2\n",
      "174    class_2\n",
      "175    class_2\n",
      "176    class_2\n",
      "177    class_2\n",
      "Length: 178, dtype: object\n",
      "OrderedDict([('Log Loss Multiclass', 0.04132737017536148)])\n"
     ]
    }
   ],
   "source": [
    "from evalml.demos import load_wine\n",
    "X, y = load_wine()\n",
    "\n",
    "pipeline = CustomMulticlassClassificationPipeline({})\n",
    "pipeline.fit(X, y)\n",
    "print(pipeline.predict(X))\n",
    "print(pipeline.score(X, y, objectives=['log loss multiclass']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Name\n",
    "By default, a pipeline class's name property is the result of adding spaces between each Pascal case capitalization in the class name. E.g. `LogisticRegressionPipeline.name` will return 'Logistic Regression Pipeline'. Therefore, we suggest custom pipelines use Pascal case for their class names.\n",
    "\n",
    "If you'd like to override the pipeline classes name attribute so it isn't derived from the class name, you can set the custom_name attribute, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A custom pipeline name\n"
     ]
    }
   ],
   "source": [
    "from evalml.pipelines import MulticlassClassificationPipeline\n",
    "\n",
    "class CustomPipeline(MulticlassClassificationPipeline):\n",
    "    component_graph = ['Imputer', 'One Hot Encoder', 'Logistic Regression Classifier']\n",
    "    custom_name = 'A custom pipeline name'\n",
    "    \n",
    "print(CustomPipeline.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Override Component Hyperparameter Ranges\n",
    "To specify custom hyperparameter ranges, set the `custom_hyperparameters` property to be a dictionary where each key-value pair consists of a parameter name and range. AutoML will use this dictionary to override the hyperparameter ranges collected from each component in the component graph.\n",
    "\n",
    "If the hyperparameter ranges are categorical values, they can be passed in as lists or as `skopt.space.Categorical` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without custom hyperparameters:\n",
      "{'Imputer': {'categorical_impute_strategy': ['most_frequent'], 'numeric_impute_strategy': ['mean', 'median', 'most_frequent']}, 'One Hot Encoder': {}, 'Standard Scaler': {}, 'Logistic Regression Classifier': {'penalty': ['l2'], 'C': Real(low=0.01, high=10, prior='uniform', transform='identity')}}\n",
      "\n",
      "With custom hyperparameters:\n",
      "{'Imputer': {'categorical_impute_strategy': ['most_frequent'], 'numeric_impute_strategy': ['mean', 'median', 'most_frequent']}, 'One Hot Encoder': {}, 'Standard Scaler': {}, 'Logistic Regression Classifier': {'penalty': ['l2'], 'C': Real(low=0.01, high=10, prior='uniform', transform='identity')}}\n"
     ]
    }
   ],
   "source": [
    "from skopt.space import Categorical\n",
    "class CustomPipeline(MulticlassClassificationPipeline):\n",
    "    component_graph = ['Imputer', 'One Hot Encoder', 'Standard Scaler', 'Logistic Regression Classifier']\n",
    "\n",
    "print(\"Without custom hyperparameters:\")\n",
    "print(CustomPipeline.hyperparameters)  \n",
    "    \n",
    "class CustomPipeline(MulticlassClassificationPipeline):\n",
    "        component_graph = ['Imputer', 'One Hot Encoder', 'Standard Scaler', 'Logistic Regression Classifier']\n",
    "        custom_hyperparameters = {\n",
    "        'Simple Imputer' : {\n",
    "            'impute_strategy': Categorical(['most_frequent']),\n",
    "            # Can also pass in a list, like below\n",
    "            'another_hyperparameter': ['value']\n",
    "        }\n",
    "    }\n",
    "\n",
    "print()\n",
    "print(\"With custom hyperparameters:\")\n",
    "print(CustomPipeline.hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize our new custom pipeline class, we must pass in a `parameters` argument. If we want to use the defaults for each component, we can simply pass in an empty dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomPipeline(parameters={'Imputer':{'categorical_impute_strategy': 'most_frequent', 'numeric_impute_strategy': 'mean', 'categorical_fill_value': None, 'numeric_fill_value': None}, 'One Hot Encoder':{'top_n': 10, 'features_to_encode': None, 'categories': None, 'drop': None, 'handle_unknown': 'ignore', 'handle_missing': 'error'}, 'Logistic Regression Classifier':{'penalty': 'l2', 'C': 1.0, 'n_jobs': -1, 'multi_class': 'auto', 'solver': 'lbfgs'},})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CustomPipeline(parameters={})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Parameters\n",
    "You can also pass in custom parameters, which will then be used when instantiating each component in `component_graph`. The parameters dictionary needs to be in the format of a two-layered dictionary where the key-value pairs are the component name and corresponding component parameters dictionary. The component parameters dictionary consists of (parameter name, parameter values) key-value pairs.\n",
    "\n",
    "An example will be shown below. The API reference for component parameters can also be found [here](../api_reference.rst#components)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "        'Imputer': {\n",
    "            \"categorical_impute_strategy\": \"most_frequent\",\n",
    "            \"numeric_impute_strategy\": \"median\"\n",
    "        },\n",
    "        'Logistic Regression Classifier': {\n",
    "            'penalty': 'l2',\n",
    "            'C': 1.0,\n",
    "        }\n",
    "    }\n",
    "\n",
    "cp = CustomPipeline(parameters=parameters, random_state=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Description\n",
    "\n",
    "You can call `.graph()` to see each component and its parameters. Each component takes in data and feeds it to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: Custom Pipeline Pages: 1 -->\n",
       "<svg width=\"837pt\" height=\"123pt\"\n",
       " viewBox=\"0.00 0.00 836.64 123.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 119)\">\n",
       "<title>Custom Pipeline</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-119 832.64,-119 832.64,4 -4,4\"/>\n",
       "<!-- Imputer -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Imputer</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-14.5 0,-100.5 266.36,-100.5 266.36,-14.5 0,-14.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"133.18\" y=\"-85.3\" font-family=\"Times,serif\" font-size=\"14.00\">Imputer</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"0,-78.5 266.36,-78.5 \"/>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-63.3\" font-family=\"Times,serif\" font-size=\"14.00\">categorical_impute_strategy : most_frequent</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-49.3\" font-family=\"Times,serif\" font-size=\"14.00\">numeric_impute_strategy : median</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-35.3\" font-family=\"Times,serif\" font-size=\"14.00\">categorical_fill_value : None</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-21.3\" font-family=\"Times,serif\" font-size=\"14.00\">numeric_fill_value : None</text>\n",
       "</g>\n",
       "<!-- One Hot Encoder -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>One Hot Encoder</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"302.36,-0.5 302.36,-114.5 468.41,-114.5 468.41,-0.5 302.36,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"385.38\" y=\"-99.3\" font-family=\"Times,serif\" font-size=\"14.00\">One Hot Encoder</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"302.36,-92.5 468.41,-92.5 \"/>\n",
       "<text text-anchor=\"start\" x=\"310.36\" y=\"-77.3\" font-family=\"Times,serif\" font-size=\"14.00\">top_n : 10</text>\n",
       "<text text-anchor=\"start\" x=\"310.36\" y=\"-63.3\" font-family=\"Times,serif\" font-size=\"14.00\">features_to_encode : None</text>\n",
       "<text text-anchor=\"start\" x=\"310.36\" y=\"-49.3\" font-family=\"Times,serif\" font-size=\"14.00\">categories : None</text>\n",
       "<text text-anchor=\"start\" x=\"310.36\" y=\"-35.3\" font-family=\"Times,serif\" font-size=\"14.00\">drop : None</text>\n",
       "<text text-anchor=\"start\" x=\"310.36\" y=\"-21.3\" font-family=\"Times,serif\" font-size=\"14.00\">handle_unknown : ignore</text>\n",
       "<text text-anchor=\"start\" x=\"310.36\" y=\"-7.3\" font-family=\"Times,serif\" font-size=\"14.00\">handle_missing : error</text>\n",
       "</g>\n",
       "<!-- Imputer&#45;&gt;One Hot Encoder -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Imputer&#45;&gt;One Hot Encoder</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M266.67,-57.5C266.67,-57.5 292.11,-57.5 292.11,-57.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"292.11,-61 302.11,-57.5 292.11,-54 292.11,-61\"/>\n",
       "</g>\n",
       "<!-- Standard Scaler -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Standard Scaler</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"504.41,-39.5 504.41,-75.5 608.65,-75.5 608.65,-39.5 504.41,-39.5\"/>\n",
       "<text text-anchor=\"start\" x=\"512.41\" y=\"-53.3\" font-family=\"Times,serif\" font-size=\"14.00\">Standard Scaler</text>\n",
       "</g>\n",
       "<!-- One Hot Encoder&#45;&gt;Standard Scaler -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>One Hot Encoder&#45;&gt;Standard Scaler</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M468.45,-57.5C468.45,-57.5 493.97,-57.5 493.97,-57.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"493.97,-61 503.97,-57.5 493.97,-54 493.97,-61\"/>\n",
       "</g>\n",
       "<!-- Logistic Regression Classifier -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>Logistic Regression Classifier</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"644.65,-7.5 644.65,-107.5 828.64,-107.5 828.64,-7.5 644.65,-7.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"736.65\" y=\"-92.3\" font-family=\"Times,serif\" font-size=\"14.00\">Logistic Regression Classifier</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"644.65,-85.5 828.64,-85.5 \"/>\n",
       "<text text-anchor=\"start\" x=\"652.65\" y=\"-70.3\" font-family=\"Times,serif\" font-size=\"14.00\">penalty : l2</text>\n",
       "<text text-anchor=\"start\" x=\"652.65\" y=\"-56.3\" font-family=\"Times,serif\" font-size=\"14.00\">C : 1.00</text>\n",
       "<text text-anchor=\"start\" x=\"652.65\" y=\"-42.3\" font-family=\"Times,serif\" font-size=\"14.00\">n_jobs : &#45;1</text>\n",
       "<text text-anchor=\"start\" x=\"652.65\" y=\"-28.3\" font-family=\"Times,serif\" font-size=\"14.00\">multi_class : auto</text>\n",
       "<text text-anchor=\"start\" x=\"652.65\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">solver : lbfgs</text>\n",
       "</g>\n",
       "<!-- Standard Scaler&#45;&gt;Logistic Regression Classifier -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>Standard Scaler&#45;&gt;Logistic Regression Classifier</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M609.11,-57.5C609.11,-57.5 634.35,-57.5 634.35,-57.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"634.35,-61 644.35,-57.5 634.35,-54 634.35,-61\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x13c134910>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see a textual representation of the pipeline by calling `.describe()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************\n",
      "* Custom Pipeline *\n",
      "*******************\n",
      "\n",
      "Problem Type: multiclass\n",
      "Model Family: Linear\n",
      "\n",
      "Pipeline Steps\n",
      "==============\n",
      "1. Imputer\n",
      "\t * categorical_impute_strategy : most_frequent\n",
      "\t * numeric_impute_strategy : median\n",
      "\t * categorical_fill_value : None\n",
      "\t * numeric_fill_value : None\n",
      "2. One Hot Encoder\n",
      "\t * top_n : 10\n",
      "\t * features_to_encode : None\n",
      "\t * categories : None\n",
      "\t * drop : None\n",
      "\t * handle_unknown : ignore\n",
      "\t * handle_missing : error\n",
      "3. Standard Scaler\n",
      "4. Logistic Regression Classifier\n",
      "\t * penalty : l2\n",
      "\t * C : 1.0\n",
      "\t * n_jobs : -1\n",
      "\t * multi_class : auto\n",
      "\t * solver : lbfgs\n"
     ]
    }
   ],
   "source": [
    "cp.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component Graph\n",
    "\n",
    "You can use the pipeline's `component_graph` attribute to access a component at a specific index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputer\n"
     ]
    }
   ],
   "source": [
    "first_component = cp.component_graph[0]\n",
    "print (first_component.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use `pipeline.get_component(name)` and provide the component name instead (API reference [here](../generated/methods/evalml.pipelines.PipelineBase.get_component.ipynb)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Imputer(categorical_impute_strategy='most_frequent', numeric_impute_strategy='median', categorical_fill_value=None, numeric_fill_value=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.get_component('Imputer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Estimator\n",
    "\n",
    "EvalML enforces that the last component of a pipeline is an estimator. You can access this estimator directly by using either `pipeline.component_graph[-1]` or `pipeline.estimator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionClassifier(penalty='l2', C=1.0, n_jobs=-1, multi_class='auto', solver='lbfgs')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.component_graph[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionClassifier(penalty='l2', C=1.0, n_jobs=-1, multi_class='auto', solver='lbfgs')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Feature Names\n",
    "\n",
    "After a pipeline is fitted, you can access a pipeline's `input_feature_names` attribute to obtain a dictionary containing a list of feature names passed to each component of the pipeline. This could be especially useful for debugging where a feature might have been dropped or detecting unexpected behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Imputer': ['alcohol',\n",
       "  'malic_acid',\n",
       "  'ash',\n",
       "  'alcalinity_of_ash',\n",
       "  'magnesium',\n",
       "  'total_phenols',\n",
       "  'flavanoids',\n",
       "  'nonflavanoid_phenols',\n",
       "  'proanthocyanins',\n",
       "  'color_intensity',\n",
       "  'hue',\n",
       "  'od280/od315_of_diluted_wines',\n",
       "  'proline'],\n",
       " 'Random Forest Classifier': ['alcohol',\n",
       "  'malic_acid',\n",
       "  'ash',\n",
       "  'alcalinity_of_ash',\n",
       "  'magnesium',\n",
       "  'total_phenols',\n",
       "  'flavanoids',\n",
       "  'nonflavanoid_phenols',\n",
       "  'proanthocyanins',\n",
       "  'color_intensity',\n",
       "  'hue',\n",
       "  'od280/od315_of_diluted_wines',\n",
       "  'proline']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.input_feature_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Code\n",
    "\n",
    "Once you have a pipeline defined in EvalML, you can generate string Python code to recreate this pipeline, which can then be saved and run elsewhere with EvalML. `generate_pipeline_code` requires a pipeline instance as the input. It can also handle custom components, but it won't return the code required to define the component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from evalml.pipelines.multiclass_classification_pipeline import MulticlassClassificationPipeline\n",
      "\n",
      "class CustomPipeline(MulticlassClassificationPipeline):\n",
      "\tcomponent_graph = [\n",
      "\t\t'Imputer',\n",
      "\t\tMyDropNullColumns,\n",
      "\t\t'DateTime Featurization Component',\n",
      "\t\t'One Hot Encoder',\n",
      "\t\t'Random Forest Classifier'\n",
      "\t]\n",
      "\tcustom_hyperparameters = {'Imputer': {'numeric_impute_strategy': ['mean', 'median']}}\n",
      "\tname = 'Custom Pipeline'\n",
      "\n",
      "parameters = {\n",
      "\t\"Imputer\": {\n",
      "\t\t\"categorical_impute_strategy\": \"most_frequent\",\n",
      "\t\t\"numeric_impute_strategy\": \"median\",\n",
      "\t\t\"categorical_fill_value\": None,\n",
      "\t\t\"numeric_fill_value\": None\n",
      "\t},\n",
      "\t\"My Drop Null Columns Transformer\": {\n",
      "\t\t\"pct_None_threshold\": 1.0\n",
      "\t},\n",
      "\t\"DateTime Featurization Component\": {\n",
      "\t\t\"features_to_extract\": [\n",
      "\t\t\t\"year\",\n",
      "\t\t\t\"month\",\n",
      "\t\t\t\"day_of_week\",\n",
      "\t\t\t\"hour\"\n",
      "\t\t]\n",
      "\t},\n",
      "\t\"One Hot Encoder\": {\n",
      "\t\t\"top_n\": 10,\n",
      "\t\t\"features_to_encode\": None,\n",
      "\t\t\"categories\": None,\n",
      "\t\t\"drop\": None,\n",
      "\t\t\"handle_unknown\": \"ignore\",\n",
      "\t\t\"handle_missing\": \"error\"\n",
      "\t},\n",
      "\t\"Random Forest Classifier\": {\n",
      "\t\t\"n_estimators\": 100,\n",
      "\t\t\"max_depth\": 6,\n",
      "\t\t\"n_jobs\": -1\n",
      "\t}\n",
      "}\n",
      "pipeline = CustomPipeline(parameters)\n",
      "             Number of Features\n",
      "Boolean                       1\n",
      "Categorical                   6\n",
      "Numeric                       5\n",
      "\n",
      "Number of training examples: 99992\n",
      "Targets\n",
      "False    84.82%\n",
      "True     15.18%\n",
      "Name: fraud, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomPipeline(parameters={'Imputer':{'categorical_impute_strategy': 'most_frequent', 'numeric_impute_strategy': 'median', 'categorical_fill_value': None, 'numeric_fill_value': None}, 'My Drop Null Columns Transformer':{'pct_null_threshold': 1.0, 'pct_None_threshold': 1.0}, 'DateTime Featurization Component':{'features_to_extract': ['year', 'month', 'day_of_week', 'hour']}, 'One Hot Encoder':{'top_n': 10, 'features_to_encode': None, 'categories': None, 'drop': None, 'handle_unknown': 'ignore', 'handle_missing': 'error'}, 'Random Forest Classifier':{'n_estimators': 100, 'max_depth': 6, 'n_jobs': -1},})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evalml.pipelines.utils import generate_pipeline_code\n",
    "from evalml.pipelines import MulticlassClassificationPipeline\n",
    "import pandas as pd\n",
    "\n",
    "class MyDropNullColumns(Transformer):\n",
    "    \"\"\"Transformer to drop features whose percentage of NaN values exceeds a specified threshold\"\"\"\n",
    "    name = \"My Drop Null Columns Transformer\"\n",
    "    hyperparameter_ranges = {}\n",
    "\n",
    "    def __init__(self, pct_null_threshold=1.0, random_state=0, **kwargs):\n",
    "        \"\"\"Initalizes an transformer to drop features whose percentage of NaN values exceeds a specified threshold.\n",
    "\n",
    "        Arguments:\n",
    "            pct_null_threshold(float): The percentage of NaN values in an input feature to drop.\n",
    "                Must be a value between [0, 1] inclusive. If equal to 0.0, will drop columns with any null values.\n",
    "                If equal to 1.0, will drop columns with all null values. Defaults to 0.95.\n",
    "        \"\"\"\n",
    "        if pct_null_threshold < 0 or pct_null_threshold > 1:\n",
    "            raise ValueError(\"pct_null_threshold must be a float between 0 and 1, inclusive.\")\n",
    "        parameters = {\"pct_null_threshold\": pct_null_threshold}\n",
    "        parameters.update(kwargs)\n",
    "\n",
    "        self._cols_to_drop = None\n",
    "        super().__init__(parameters=parameters,\n",
    "                         component_obj=None,\n",
    "                         random_state=random_state)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        pct_null_threshold = self.parameters[\"pct_null_threshold\"]\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        percent_null = X.isnull().mean()\n",
    "        if pct_null_threshold == 0.0:\n",
    "            null_cols = percent_null[percent_null > 0]\n",
    "        else:\n",
    "            null_cols = percent_null[percent_null >= pct_null_threshold]\n",
    "        self._cols_to_drop = list(null_cols.index)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        \"\"\"Transforms data X by dropping columns that exceed the threshold of null values.\n",
    "        Arguments:\n",
    "            X (pd.DataFrame): Data to transform\n",
    "            y (pd.Series, optional): Targets\n",
    "        Returns:\n",
    "            pd.DataFrame: Transformed X\n",
    "        \"\"\"\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        return X.drop(columns=self._cols_to_drop, axis=1)\n",
    "\n",
    "class CustomPipeline(MulticlassClassificationPipeline):\n",
    "    name = \"Custom Pipeline\"\n",
    "    component_graph = ['Imputer', MyDropNullColumns, 'DateTime Featurization Component', 'One Hot Encoder', 'Random Forest Classifier']\n",
    "    custom_hyperparameters={\n",
    "        \"Imputer\": {\n",
    "            \"numeric_impute_strategy\": ['mean', 'median']\n",
    "        }\n",
    "    }\n",
    "\n",
    "pipeline_instance = CustomPipeline(parameters={\"Imputer\": {\"numeric_impute_strategy\": \"median\"}})\n",
    "code = generate_pipeline_code(pipeline_instance)\n",
    "print(code)\n",
    "\n",
    "# This string can then be pasted into a separate window and run, although since the pipeline has custom component `MyDropNullColumns`, \n",
    "#      the code for that component must also be included\n",
    "\n",
    "from evalml.demos import load_fraud\n",
    "X, y = load_fraud()\n",
    "exec(code)\n",
    "pipeline.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}