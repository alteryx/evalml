{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this guide, we'll show how you can use EvalML to automatically find the best pipeline for predicting whether a patient has breast cancer. Along the way, we'll highlight EvalML's built-in tools and features for understanding and interacting with the search process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-17 19:45:06,386 featuretools - WARNING    Featuretools failed to load plugin nlp_primitives from library nlp_primitives. For a full stack trace, set logging to debug.\n"
     ]
    }
   ],
   "source": [
    "import evalml\n",
    "from evalml import AutoMLSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load in the features and outcomes we want to use to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = evalml.demos.load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EvalML has many options to configure the pipeline search. At the minimum, we need to define an objective function. For simplicity, we will use the F1 score in this example. However, the real power of EvalML is in using domain-specific [objective functions](user_guide/objectives.ipynb) or [building your own](user_guide/objectives.ipynb).\n",
    "\n",
    "Below EvalML utilizes Bayesian optimization (EvalML's default optimizer) to search and find the best pipeline defined by the given objective.\n",
    "\n",
    "EvalML provides a number of parameters to control the search process. `max_batches` is one of the parameters which controls the stopping criterion for the AutoML search. It indicates the maximum number of rounds of AutoML to evaluate, where each round may train and score a variable number of pipelines. In this example, `max_batches` is set to 1.\n",
    "\n",
    "** Graphing methods, like AutoMLSearch, on Jupyter Notebook and Jupyter Lab require [ipywidgets](https://ipywidgets.readthedocs.io/en/latest/user_install.html) to be installed.\n",
    "\n",
    "** If graphing on Jupyter Lab, [jupyterlab-plotly](https://plotly.com/python/getting-started/#jupyterlab-support-python-35) required. To download this, make sure you have [npm](https://nodejs.org/en/download/) installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = AutoMLSearch(problem_type=\"binary\", objective=\"f1\", max_batches=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to validate the results of the pipeline creation and optimization process, we will save some of our data as a holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_holdout, y_train, y_holdout = evalml.preprocessing.split_data(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ To provide data to EvalML, it is recommended that you create a `DataTable` object using [the Woodwork project](https://woodwork.alteryx.com/en/stable/). Here, `split_data()` returns Woodwork data structures.\n",
    "\n",
    "EvalML also accepts and works well with pandas `DataFrames`. But using the `DataTable` makes it easy to control how EvalML will treat each feature, as a numeric feature, a categorical feature, a text feature or other type of feature. Woodwork's `DataTable` includes features like inferring when a categorical feature should be treated as a text feature. For this reason, if you don't provide Woodwork objects, EvalML will raise a warning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we call `search()`, the search for the best pipeline will begin. There is no need to wrangle with missing data or categorical variables as EvalML includes various preprocessing steps (like imputation, one-hot encoding, feature selection) to ensure you're getting the best results. As long as your data is in a single table, EvalML can handle it. If not, you can reduce your data to a single table by utilizing [Featuretools](https://featuretools.featurelabs.com) and its Entity Sets.\n",
    "\n",
    "You can find more information on pipeline components and how to integrate your own custom pipelines into EvalML [here](user_guide/pipelines.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating pipelines to search over...\n",
      "*****************************\n",
      "* Beginning pipeline search *\n",
      "*****************************\n",
      "\n",
      "Optimizing for F1. \n",
      "Greater score is better.\n",
      "\n",
      "Searching up to 1 batches for a total of 9 pipelines. \n",
      "Allowed model families: lightgbm, random_forest, catboost, extra_trees, linear_model, xgboost, decision_tree\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "086302ff90f041388805794c41a2de4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'mode': 'lines+markers',\n",
       "              'name': 'Best Score',\n",
       "              'type'\u2026"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: (1/9) Mode Baseline Binary Classification P... Elapsed:00:00\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.000\n",
      "Batch 1: (2/9) Logistic Regression Classifier w/ Imp... Elapsed:00:00\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.982\n",
      "Batch 1: (3/9) Random Forest Classifier w/ Imputer      Elapsed:00:05\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.949\n",
      "Batch 1: (4/9) XGBoost Classifier w/ Imputer            Elapsed:00:07\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.965\n",
      "Batch 1: (5/9) CatBoost Classifier w/ Imputer           Elapsed:00:07\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.939\n",
      "Batch 1: (6/9) Elastic Net Classifier w/ Imputer + S... Elapsed:00:08\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.514\n",
      "High coefficient of variation (cv >= 0.2) within cross validation scores. Elastic Net Classifier w/ Imputer + Standard Scaler may not perform as estimated on unseen data.\n",
      "Batch 1: (7/9) Extra Trees Classifier w/ Imputer        Elapsed:00:08\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.945\n",
      "Batch 1: (8/9) LightGBM Classifier w/ Imputer           Elapsed:00:10\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.953\n",
      "Batch 1: (9/9) Decision Tree Classifier w/ Imputer      Elapsed:00:11\n",
      "\tStarting cross validation\n",
      "\tFinished cross validation - mean F1: 0.908\n",
      "\n",
      "Search finished after 00:12            \n",
      "Best pipeline: Logistic Regression Classifier w/ Imputer + Standard Scaler\n",
      "Best pipeline F1: 0.982089\n"
     ]
    }
   ],
   "source": [
    "automl.search(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the search is finished we can view all of the pipelines searched, ranked by score. Internally, EvalML performs cross validation to score the pipelines. If it notices a high variance across cross validation folds, it will warn you. EvalML also provides additional [data checks](user_guide/data_checks.ipynb) to analyze your data to assist you in producing the best performing pipeline. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pipeline_name</th>\n",
       "      <th>score</th>\n",
       "      <th>validation_score</th>\n",
       "      <th>percent_better_than_baseline</th>\n",
       "      <th>high_variance_cv</th>\n",
       "      <th>parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Logistic Regression Classifier w/ Imputer + St...</td>\n",
       "      <td>0.982089</td>\n",
       "      <td>0.991150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Imputer': {'categorical_impute_strategy': 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>XGBoost Classifier w/ Imputer</td>\n",
       "      <td>0.964753</td>\n",
       "      <td>0.973451</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Imputer': {'categorical_impute_strategy': 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>LightGBM Classifier w/ Imputer</td>\n",
       "      <td>0.952871</td>\n",
       "      <td>0.954128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Imputer': {'categorical_impute_strategy': 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Random Forest Classifier w/ Imputer</td>\n",
       "      <td>0.948698</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Imputer': {'categorical_impute_strategy': 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>Extra Trees Classifier w/ Imputer</td>\n",
       "      <td>0.945222</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Imputer': {'categorical_impute_strategy': 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>CatBoost Classifier w/ Imputer</td>\n",
       "      <td>0.939090</td>\n",
       "      <td>0.917431</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Imputer': {'categorical_impute_strategy': 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>Decision Tree Classifier w/ Imputer</td>\n",
       "      <td>0.907870</td>\n",
       "      <td>0.955752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Imputer': {'categorical_impute_strategy': 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>Elastic Net Classifier w/ Imputer + Standard S...</td>\n",
       "      <td>0.513875</td>\n",
       "      <td>0.658824</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>{'Imputer': {'categorical_impute_strategy': 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Mode Baseline Binary Classification Pipeline</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>{'Baseline Classifier': {'strategy': 'mode'}}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                      pipeline_name     score  \\\n",
       "0   1  Logistic Regression Classifier w/ Imputer + St...  0.982089   \n",
       "1   3                      XGBoost Classifier w/ Imputer  0.964753   \n",
       "2   7                     LightGBM Classifier w/ Imputer  0.952871   \n",
       "3   2                Random Forest Classifier w/ Imputer  0.948698   \n",
       "4   6                  Extra Trees Classifier w/ Imputer  0.945222   \n",
       "5   4                     CatBoost Classifier w/ Imputer  0.939090   \n",
       "6   8                Decision Tree Classifier w/ Imputer  0.907870   \n",
       "7   5  Elastic Net Classifier w/ Imputer + Standard S...  0.513875   \n",
       "8   0       Mode Baseline Binary Classification Pipeline  0.000000   \n",
       "\n",
       "   validation_score  percent_better_than_baseline  high_variance_cv  \\\n",
       "0          0.991150                           NaN             False   \n",
       "1          0.973451                           NaN             False   \n",
       "2          0.954128                           NaN             False   \n",
       "3          0.945455                           NaN             False   \n",
       "4          0.925926                           NaN             False   \n",
       "5          0.917431                           NaN             False   \n",
       "6          0.955752                           NaN             False   \n",
       "7          0.658824                           NaN              True   \n",
       "8          0.000000                           NaN             False   \n",
       "\n",
       "                                          parameters  \n",
       "0  {'Imputer': {'categorical_impute_strategy': 'm...  \n",
       "1  {'Imputer': {'categorical_impute_strategy': 'm...  \n",
       "2  {'Imputer': {'categorical_impute_strategy': 'm...  \n",
       "3  {'Imputer': {'categorical_impute_strategy': 'm...  \n",
       "4  {'Imputer': {'categorical_impute_strategy': 'm...  \n",
       "5  {'Imputer': {'categorical_impute_strategy': 'm...  \n",
       "6  {'Imputer': {'categorical_impute_strategy': 'm...  \n",
       "7  {'Imputer': {'categorical_impute_strategy': 'm...  \n",
       "8      {'Baseline Classifier': {'strategy': 'mode'}}  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "automl.rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are interested in see more details about the pipeline, we can view a summary description using the `id` from the rankings table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********************************\n",
      "* XGBoost Classifier w/ Imputer *\n",
      "*********************************\n",
      "\n",
      "Problem Type: binary\n",
      "Model Family: XGBoost\n",
      "\n",
      "Pipeline Steps\n",
      "==============\n",
      "1. Imputer\n",
      "\t * categorical_impute_strategy : most_frequent\n",
      "\t * numeric_impute_strategy : mean\n",
      "\t * categorical_fill_value : None\n",
      "\t * numeric_fill_value : None\n",
      "2. XGBoost Classifier\n",
      "\t * eta : 0.1\n",
      "\t * max_depth : 6\n",
      "\t * min_child_weight : 1\n",
      "\t * n_estimators : 100\n",
      "\n",
      "Training\n",
      "========\n",
      "Training for binary problems.\n",
      "Total training time (including CV): 0.6 seconds\n",
      "\n",
      "Cross Validation\n",
      "----------------\n",
      "               F1  MCC Binary  Log Loss Binary   AUC  Precision  Balanced Accuracy Binary  Accuracy Binary # Training # Testing\n",
      "0           0.973       0.958            0.050 0.998      0.982                     0.977            0.980    303.000   152.000\n",
      "1           0.957       0.930            0.117 0.986      0.948                     0.967            0.967    303.000   152.000\n",
      "2           0.964       0.943            0.090 0.992      0.964                     0.972            0.974    304.000   151.000\n",
      "mean        0.965       0.944            0.086 0.992      0.965                     0.972            0.974          -         -\n",
      "std         0.008       0.014            0.034 0.006      0.017                     0.005            0.007          -         -\n",
      "coef of var 0.009       0.015            0.396 0.006      0.018                     0.005            0.007          -         -\n"
     ]
    }
   ],
   "source": [
    "automl.describe_pipeline(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view the pipeline parameters directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Imputer': {'categorical_impute_strategy': 'most_frequent', 'numeric_impute_strategy': 'mean', 'categorical_fill_value': None, 'numeric_fill_value': None}, 'XGBoost Classifier': {'eta': 0.1, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 100}}\n"
     ]
    }
   ],
   "source": [
    "pipeline = automl.get_pipeline(3)\n",
    "print(pipeline.parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now select the best pipeline and score it on our holdout data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('F1', 0.9268292682926829)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = automl.best_pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "pipeline.score(X_holdout, y_holdout, [\"f1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the structure of the components contained by the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: Logistic Regression Classifier w/ Imputer + Standard Scaler Pages: 1 -->\n",
       "<svg width=\"635pt\" height=\"109pt\"\n",
       " viewBox=\"0.00 0.00 634.59 109.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 105)\">\n",
       "<title>Logistic Regression Classifier w/ Imputer + Standard Scaler</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-105 630.59,-105 630.59,4 -4,4\"/>\n",
       "<!-- Imputer -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Imputer</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"0,-7.5 0,-93.5 266.36,-93.5 266.36,-7.5 0,-7.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"133.18\" y=\"-78.3\" font-family=\"Times,serif\" font-size=\"14.00\">Imputer</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"0,-71.5 266.36,-71.5 \"/>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-56.3\" font-family=\"Times,serif\" font-size=\"14.00\">categorical_impute_strategy : most_frequent</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-42.3\" font-family=\"Times,serif\" font-size=\"14.00\">numeric_impute_strategy : mean</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-28.3\" font-family=\"Times,serif\" font-size=\"14.00\">categorical_fill_value : None</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">numeric_fill_value : None</text>\n",
       "</g>\n",
       "<!-- Standard Scaler -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Standard Scaler</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"302.36,-32.5 302.36,-68.5 406.6,-68.5 406.6,-32.5 302.36,-32.5\"/>\n",
       "<text text-anchor=\"start\" x=\"310.36\" y=\"-46.3\" font-family=\"Times,serif\" font-size=\"14.00\">Standard Scaler</text>\n",
       "</g>\n",
       "<!-- Imputer&#45;&gt;Standard Scaler -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Imputer&#45;&gt;Standard Scaler</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M266.38,-50.5C266.38,-50.5 292.35,-50.5 292.35,-50.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"292.35,-54 302.35,-50.5 292.35,-47 292.35,-54\"/>\n",
       "</g>\n",
       "<!-- Logistic Regression Classifier -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Logistic Regression Classifier</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"442.6,-0.5 442.6,-100.5 626.59,-100.5 626.59,-0.5 442.6,-0.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"534.6\" y=\"-85.3\" font-family=\"Times,serif\" font-size=\"14.00\">Logistic Regression Classifier</text>\n",
       "<polyline fill=\"none\" stroke=\"black\" points=\"442.6,-78.5 626.59,-78.5 \"/>\n",
       "<text text-anchor=\"start\" x=\"450.6\" y=\"-63.3\" font-family=\"Times,serif\" font-size=\"14.00\">penalty : l2</text>\n",
       "<text text-anchor=\"start\" x=\"450.6\" y=\"-49.3\" font-family=\"Times,serif\" font-size=\"14.00\">C : 1.00</text>\n",
       "<text text-anchor=\"start\" x=\"450.6\" y=\"-35.3\" font-family=\"Times,serif\" font-size=\"14.00\">n_jobs : &#45;1</text>\n",
       "<text text-anchor=\"start\" x=\"450.6\" y=\"-21.3\" font-family=\"Times,serif\" font-size=\"14.00\">multi_class : auto</text>\n",
       "<text text-anchor=\"start\" x=\"450.6\" y=\"-7.3\" font-family=\"Times,serif\" font-size=\"14.00\">solver : lbfgs</text>\n",
       "</g>\n",
       "<!-- Standard Scaler&#45;&gt;Logistic Regression Classifier -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>Standard Scaler&#45;&gt;Logistic Regression Classifier</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M407.06,-50.5C407.06,-50.5 432.3,-50.5 432.3,-50.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"432.3,-54 442.3,-50.5 432.3,-47 432.3,-54\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x144640b10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.graph()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}