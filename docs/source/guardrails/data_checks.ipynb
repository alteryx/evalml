{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Data Checks in AutoML\n",
    "\n",
    "The ultimate goal of machine learning is to make accurate predictions on unseen data. EvalML aims to help you build a model that will perform as you expect once it is deployed in to the real world.\n",
    "\n",
    "One of the benefits of using EvalML to build models is that it provides data checks to ensure you are building pipelines that will perform reliably in the future. This page describes how data checks are and can be used during the search process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evalml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Default data checks in AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, AutoML will run the series of data checks in `DefaultDataChecks` when `automl.search()` is called to check that inputs are valid before running the search and fitting pipelines. Currently, `DefaultDataChecks` contains a data check to check if a column is more 95% or more null, since that likely indicates a column with no or minimal useful information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data checks returns any error or warning messages, `automl.search()` will raise a `ValueError` and quit before searching. This allows users to address any issues before running the potentially time-intensive search process. For example, here we have some data that contain a lot of null values, causing `DefaultDataChecks` to raise a `ValueError` when try to run the search below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X = pd.DataFrame({'lots_of_null': [None] * 19 + [5],\n",
    "                     'no_null': range(20)})\n",
    "y = pd.Series([1,0]*10)\n",
    "automl = evalml.AutoClassificationSearch(max_pipelines=1)\n",
    "automl.search(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([1,0]*10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access the exact warning and error messages our data checks returned, we can access `automl.latest_data_check_results`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in automl.latest_data_check_results:\n",
    "    print (message.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using your own data check with AutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd prefer to pass in your own data check, you can do so by passing in a `DataChecks` object as the value for the `data_checks`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from evalml.data_checks import DataCheck, DataChecks\n",
    "from evalml.data_checks.data_check_message import DataCheckWarning\n",
    "\n",
    "class ZeroVarianceDataCheck(DataCheck):\n",
    "    def validate(self, X, y):\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X = pd.DataFrame(X)\n",
    "        warning_msg = \"Column '{}' has zero variance\"\n",
    "        return [DataCheckWarning(warning_msg.format(column), self.name) for column in X.columns if len(X[column].unique()) == 1]\n",
    "\n",
    "\n",
    "data_checks = DataChecks(data_checks=[ZeroVarianceDataCheck()])\n",
    "\n",
    "X = pd.DataFrame({'no_var': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "                  'any_average_col': [2, 0, 1, 2, 1, 2, 0, 1, 2, 1],\n",
    "                  'another_average_col': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]})\n",
    "y = pd.Series([0,1,1,0,0,0,1,1,0,0])\n",
    "\n",
    "automl = evalml.AutoClassificationSearch(max_pipelines=1)\n",
    "automl.search(X, y, data_checks=data_checks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing the `latest_data_check_results` will help us begin to address the issues raised by data checks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in automl.latest_data_check_results:\n",
    "    print (message.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disabling Data Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd prefer not to run any data checks before running search, you can provide an `EmptyDataChecks` instance to `search()` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalml.data_checks import EmptyDataChecks\n",
    "import pandas as pd\n",
    "\n",
    "automl = evalml.AutoClassificationSearch(max_pipelines=1)\n",
    "automl.search(X, y, data_checks=EmptyDataChecks())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike above, no data checks will be run and hence, the same input data we used above will not raise an error and continue with the search process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "nbsphinx": {
   "allow_errors": true,
   "suppress_warnings": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
