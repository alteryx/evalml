{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoML Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we saw in [pipelines and components](../pipelines/overview.html), EvalML pipelines are created by individual components with its own set of `hyper-parameters`. In machine learning, `hyper-parameters` are parameters that are selected before the learning process begins (as opposed to `learned parameters`). EvalML's automl models search for the best performing pipeline through an interative cycle of initializing new pipelines, scoring them, and then learning from the old pipelines hyper-parameters and score to initialize the next pipeline. This process is called Bayesian Optimization. Various other tuning techniques include grid-search, random-search, evolutionary and gradient techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Custom Tuners\n",
    "\n",
    "You can utilize your own tuners by passing it to any AutoML model that EvalML offers. To ensure that your tuner works with EvaML, it must follow the following API:\n",
    "\n",
    "```python\n",
    "# TBD\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evalml import AutoClassifier\n",
    "from evalml.tuners import SKOptTuner\n",
    "\n",
    "myTuner = SKOptTuner\n",
    "clf = AutoClassifier(objective='recall', tuner=myTuner)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
